{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dcab6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# unary\n",
    "class Power(AbstractPrimitive):\n",
    "    def __init__(self,power):\n",
    "        super().__init__(locals())\n",
    "        self.power=power\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.pow(x,self.power)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sqrt(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps = eps\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.pow(torch.maximum(x,torch.tensor(self.eps).repeat(x.shape).cuda()),.5)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sin(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sin(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Cos(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.cos(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Abs_op(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.abs(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sign(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x*-1\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_mul(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x * self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_add(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x + self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Log(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps = eps\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.log(torch.maximum(x,torch.tensor(self.eps).repeat(x.shape).cuda()))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        x=torch.exp(x)\n",
    "        x=torch.clamp(x,max=88)\n",
    "        return x\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        x=torch.clamp(x,min=-89,max=89)\n",
    "        return torch.sinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Cosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        x=torch.clamp(x,min=-89,max=89)\n",
    "        return torch.cosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Tanh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.tanh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Asinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.asinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Acosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.acosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Atan(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.atan(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinc(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sinc(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.maximum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.minimum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Sigmoid(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sigmoid(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class LogExp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        x=torch.log(1+torch.exp(x))\n",
    "        x=torch.clamp(x,max=88)\n",
    "        return x\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp2(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-torch.pow(x,2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Erf(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.erf(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f21927",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#binary\n",
    "class Add(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.add(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sub(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sub(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Mul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.mul(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Div(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps=eps\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.div(x[0],x[1] + self.eps)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.maximum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.minimum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class SigMul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.mul(torch.sigmoid(x[0]),x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSub2(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.pow(torch.sub(x[0],x[1]),2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSubAbs(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.abs(torch.sub(x[0],x[1])))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class BetaMix(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.add(-self.beta*x[0],(1-self.beta)*x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}