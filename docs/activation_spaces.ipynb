{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from naslib.defaults.trainer import Trainer\n",
    "from naslib.optimizers import DARTSOptimizer\n",
    "from naslib.search_spaces import DartsSearchSpace\n",
    "from naslib.utils import utils, setup_logger, get_config_from_args, set_seed, log_args\n",
    "from naslib.search_spaces.core.graph import Graph, EdgeData\n",
    "from naslib.search_spaces.core import primitives as ops\n",
    "from torch import nn\n",
    "from fvcore.common.config import CfgNode\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from naslib.search_spaces.core.primitives import AbstractPrimitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mdataset....................................cifar10\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mseed.............................................0\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0msearch_space...........................nasbench201\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mout_dir........................................run\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0moptimizer....................................darts\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0msearchacq_fn_optimization: random_sampling\n",
      "acq_fn_type: its\n",
      "arch_learning_rate: 0.0003\n",
      "arch_weight_decay: 0.001\n",
      "batch_size: 256\n",
      "checkpoint_freq: 1000\n",
      "cutout: False\n",
      "cutout_length: 16\n",
      "cutout_prob: 1.0\n",
      "data_size: 25000\n",
      "debug_predictor: False\n",
      "drop_path_prob: 0.0\n",
      "encoding_type: adjacency_one_hot\n",
      "epochs: 100\n",
      "fidelity: -1\n",
      "gpu: None\n",
      "grad_clip: 5\n",
      "k: 10\n",
      "learning_rate: 0.025\n",
      "learning_rate_min: 0.001\n",
      "max_mutations: 1\n",
      "momentum: 0.9\n",
      "num_arches_to_mutate: 2\n",
      "num_candidates: 20\n",
      "num_ensemble: 3\n",
      "num_init: 10\n",
      "output_weights: True\n",
      "population_size: 30\n",
      "predictor_type: var_sparse_gp\n",
      "sample_size: 10\n",
      "seed: 0\n",
      "tau_max: 10\n",
      "tau_min: 0.1\n",
      "train_portion: 0.7\n",
      "unrolled: False\n",
      "warm_start_epochs: 0\n",
      "weight_decay: 0.0003\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mevaluationauxiliary_weight: 0.4\n",
      "batch_size: 96\n",
      "checkpoint_freq: 30\n",
      "cutout: True\n",
      "cutout_length: 16\n",
      "cutout_prob: 1.0\n",
      "data_size: 50000\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://127.0.0.1:8888\n",
      "drop_path_prob: 0.2\n",
      "epochs: 600\n",
      "gpu: None\n",
      "grad_clip: 5\n",
      "learning_rate: 0.025\n",
      "learning_rate_min: 0.0\n",
      "momentum: 0.9\n",
      "multiprocessing_distributed: False\n",
      "rank: 0\n",
      "train_portion: 1.0\n",
      "warm_start_epochs: 0\n",
      "weight_decay: 0.0003\n",
      "world_size: 1\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0meval_only....................................False\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mresume.......................................False\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mmodel_path....................................None\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mgpu...........................................None\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0msave.........................run/cifar10/bananas/0\n",
      "\u001b[32m[07/05 11:41:40 nl.utils.utils]: \u001b[0mdata../project/dl2022s/robertsj/NASLib/naslib/data\n"
     ]
    }
   ],
   "source": [
    "config = utils.get_config_from_args(config_type='nas')\n",
    "config.optimizer = 'darts'\n",
    "utils.set_seed(config.seed)\n",
    "clear_output(wait=True)\n",
    "utils.log_args(config)\n",
    "\n",
    "logger = setup_logger(config.save + '/log.log')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Power(AbstractPrimitive):\n",
    "    def __init__(self,power):\n",
    "        super().__init__(locals())\n",
    "        self.power=power\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.pow(x,self.power)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sin(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.sin(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Cos(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.cos(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Abs_op(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.abs(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sign(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return x*-1\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_mul(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return x * self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_add(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return x + self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Log(AbstractPrimitive):\n",
    "    def __init__(self, eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps = eps\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.log(x+self.eps)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.exp(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.sinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Cosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.cosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Tanh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.tanh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Asinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.asinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Acosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.acosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Atan(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.atan(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinc(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.sinc(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.maximum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.minimum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Sigmoid(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.sigmoid(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class LogExp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.log(1+torch.exp(x))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp2(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.exp(-torch.pow(x,2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Erf(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.erf(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Add(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.add(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sub(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.sub(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Mul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.mul(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Div(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps=eps\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.div(x[0],x[1] + self.eps)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.maximum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.minimum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class SigMul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.mul(torch.sigmoid(x[0]),x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSub2(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.pow(torch.sub(x[0],x[1]),2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSubAbs(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.abs(torch.sub(x[0],x[1])))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class BetaMix(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self, x, edge_data=None):\n",
    "        return torch.add(-self.beta*x[0],(1-self.beta)*x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'a_stage_2'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        stages = ['a_stage_1', 'a_stage_2']\n",
    "\n",
    "        # cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'activation_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2) # intermediate node\n",
    "        activation_cell.add_node(3) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData())]) # mutable intermediate edge\n",
    "        activation_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable output edge\n",
    "\n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        for i, scope in zip(range(3, 5), stages):\n",
    "            self.add_node(i, subgraph=deepcopy(activation_cell).set_scope(scope).set_input([i-1])) # activation cell i\n",
    "            self.nodes[i]['subgraph'].name = scope\n",
    "        self.add_node(5) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 5)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[4, 5].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            )\n",
    "\n",
    "    def _set_ops(self, edge):\n",
    "        edge.data.set('op', [\n",
    "            ops.Sequential(nn.ReLU()),\n",
    "            ops.Sequential(nn.Hardswish()),\n",
    "            ops.Sequential(nn.LeakyReLU()),\n",
    "            ops.Sequential(nn.Identity())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stack():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, tensors, edges_data=None):\n",
    "        return torch.stack(tensors)\n",
    "\n",
    "\n",
    "class ComplexSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'u_stage_1',\n",
    "        'u_stage_2',\n",
    "        'b_stage_1'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        u_stages = ['u_stage_1', 'u_stage_2']\n",
    "        \n",
    "        # unary cell definition\n",
    "        unary_cell = Graph()\n",
    "        unary_cell.name = 'u_cell'\n",
    "        unary_cell.add_node(1) # input node\n",
    "        unary_cell.add_node(2) # intermediate node\n",
    "        unary_cell.add_node(3) # output node\n",
    "        unary_cell.add_edges_from([(1, 2, EdgeData())]) # mutable edge\n",
    "        unary_cell.edges[1, 2].set('cell_name', 'u_cell')\n",
    "        unary_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable edge\n",
    "        \n",
    "        # binary cell definition\n",
    "        binary_cell = Graph()\n",
    "        binary_cell.name = 'b_cell'\n",
    "        binary_cell.add_node(1) # input node\n",
    "        binary_cell.add_node(2) # input node\n",
    "        binary_cell.add_node(3) # concatination node\n",
    "        binary_cell.nodes[3]['comb_op'] = stack()\n",
    "        binary_cell.add_node(4) # intermediate node\n",
    "        binary_cell.add_node(5) # output node\n",
    "        binary_cell.add_edges_from([(3, 4, EdgeData())]) # mutable edge\n",
    "        binary_cell.edges[3, 4].set('cell_name', 'b_cell') \n",
    "        binary_cell.add_edges_from([(1, 3, EdgeData().finalize()),\n",
    "                                    (2, 3, EdgeData().finalize()),\n",
    "                                    (4, 5, EdgeData().finalize())]) # immutable edges\n",
    "        \n",
    "        # activation cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'a_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2, subgraph=deepcopy(unary_cell).set_scope('u_stage_1').set_input([1])) # unary node\n",
    "        activation_cell.nodes[2]['subgraph'].name = 'u_stage_1'\n",
    "        activation_cell.add_node(3, subgraph=deepcopy(unary_cell).set_scope('u_stage_2').set_input([1])) # unary node\n",
    "        activation_cell.nodes[3]['subgraph'].name = 'u_stage_2'\n",
    "        activation_cell.add_node(4, subgraph=deepcopy(binary_cell).set_scope('b_stage_1').set_input([2, 3])) # binary node\n",
    "        activation_cell.nodes[4]['subgraph'].name = 'b_stage_1'\n",
    "        activation_cell.add_node(5) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize()), \n",
    "                                        (1, 3, EdgeData().finalize()),\n",
    "                                        (2, 4, EdgeData().finalize()),\n",
    "                                        (3, 4, EdgeData().finalize()), \n",
    "                                        (4, 5, EdgeData().finalize())])\n",
    "        \n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        self.add_node(3, subgraph=deepcopy(activation_cell).set_input([2])) # activation cell\n",
    "        self.nodes[3]['subgraph'].name = 'a_stage_1'\n",
    "        self.add_node(4) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 4)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[3, 4].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in u_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_unary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            ) # set unary cell ops\n",
    "        \n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_binary_ops(edge),\n",
    "            scope='b_stage_1',\n",
    "            private_edge_data=True\n",
    "        ) # set binary cell ops\n",
    "        \n",
    "\n",
    "    def _set_unary_ops(self, edge):\n",
    "        edge.data.set('op', [ops.Identity(), ops.Zero(stride=1)]) \n",
    "        \n",
    "        \n",
    "    def _set_binary_ops(self, edge):\n",
    "        edge.data.set('op', [Minimum(), Maximum()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'u_stage_1',\n",
    "        'u_stage_2',\n",
    "        'u_stage_3',\n",
    "        'u_stage_4',\n",
    "        'b_stage_1',\n",
    "        'b_stage_2'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        u_stages = ['u_stage_1', 'u_stage_2', 'u_stage_3', 'u_stage_4']\n",
    "        b_stages = ['b_stage_1', 'b_stage_2']\n",
    "        \n",
    "        # unary cell definition\n",
    "        unary_cell = Graph()\n",
    "        unary_cell.name = 'u_cell'\n",
    "        unary_cell.add_node(1) # input node\n",
    "        unary_cell.add_node(2) # intermediate node\n",
    "        unary_cell.add_node(3) # output node\n",
    "        unary_cell.add_edges_from([(1, 2, EdgeData())]) # mutable edge\n",
    "        unary_cell.edges[1, 2].set('cell_name', 'u_cell')\n",
    "        unary_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable edge\n",
    "        \n",
    "        # binary cell definition\n",
    "        binary_cell = Graph()\n",
    "        binary_cell.name = 'b_cell'\n",
    "        binary_cell.add_node(1) # input node\n",
    "        binary_cell.add_node(2) # input node\n",
    "        binary_cell.add_node(3) # concatination node\n",
    "        binary_cell.nodes[3]['comb_op'] = stack()\n",
    "        binary_cell.add_node(4) # intermediate node\n",
    "        binary_cell.add_node(5) # output node\n",
    "        binary_cell.add_edges_from([(3, 4, EdgeData())]) # mutable edge\n",
    "        binary_cell.edges[3, 4].set('cell_name', 'b_cell') \n",
    "        binary_cell.add_edges_from([(1, 3, EdgeData().finalize()),\n",
    "                                    (2, 3, EdgeData().finalize()),\n",
    "                                    (4, 5, EdgeData().finalize())]) # immutable edges\n",
    "        \n",
    "        # activation cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'a_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2, subgraph=deepcopy(unary_cell).set_scope('u_stage_1').set_input([1])) # unary cell 1\n",
    "        activation_cell.nodes[2]['subgraph'].name = 'u_stage_1'\n",
    "        activation_cell.add_node(3, subgraph=deepcopy(unary_cell).set_scope('u_stage_2').set_input([1])) # unary cell 2\n",
    "        activation_cell.nodes[3]['subgraph'].name = 'u_stage_2'\n",
    "        activation_cell.add_node(4, subgraph=deepcopy(unary_cell).set_scope('u_stage_3').set_input([1])) # unary cell 3\n",
    "        activation_cell.nodes[4]['subgraph'].name = 'u_stage_3'\n",
    "        activation_cell.add_node(5, subgraph=deepcopy(binary_cell).set_scope('b_stage_1').set_input([2, 3])) # binary cell 1\n",
    "        activation_cell.nodes[5]['subgraph'].name = 'b_stage_1'\n",
    "        activation_cell.add_node(6, subgraph=deepcopy(unary_cell).set_scope('u_stage_4').set_input([5])) # unary cell 4\n",
    "        activation_cell.nodes[6]['subgraph'].name = 'u_stage_4'\n",
    "        activation_cell.add_node(7, subgraph=deepcopy(binary_cell).set_scope('b_stage_2').set_input([4, 6])) # binary cell 2\n",
    "        activation_cell.nodes[7]['subgraph'].name = 'b_stage_2'\n",
    "        activation_cell.add_node(8) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize()), \n",
    "                                        (1, 3, EdgeData().finalize()),\n",
    "                                        (1, 4, EdgeData().finalize()),\n",
    "                                        (2, 5, EdgeData().finalize()),\n",
    "                                        (3, 5, EdgeData().finalize()), \n",
    "                                        (4, 7, EdgeData().finalize()),\n",
    "                                        (5, 6, EdgeData().finalize()),\n",
    "                                        (6, 7, EdgeData().finalize()),\n",
    "                                        (7, 8, EdgeData().finalize())])\n",
    "        \n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        self.add_node(3, subgraph=deepcopy(activation_cell).set_input([2])) # activation cell\n",
    "        self.add_node(4) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 4)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[3, 4].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in u_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_unary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            ) # set unary cell ops\n",
    "        \n",
    "        for scope in b_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_binary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True\n",
    "            ) # set binary cell ops\n",
    "        \n",
    "\n",
    "    def _set_unary_ops(self, edge, channels=None):\n",
    "        edge.data.set('op', [\n",
    "            ops.Identity(), \n",
    "            ops.Zero(stride=1)\n",
    "        ]) \n",
    "        \n",
    "        \n",
    "    def _set_binary_ops(self, edge, channels=None):\n",
    "        edge.data.set('op', [\n",
    "            Minimum(),\n",
    "            Maximum(),\n",
    "        ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResNet20SearchSpace(Graph):\n",
    "    \"\"\"\n",
    "    https://www.researchgate.net/figure/ResNet-20-architecture_fig3_351046093\n",
    "    \"\"\"\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        f\"activation_{i}\" for i in range(1, 20)\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'activation_cell'\n",
    "        activation_cell.add_node(1)  # input node\n",
    "        activation_cell.add_node(2)  # intermediate node\n",
    "        activation_cell.add_node(3)  # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData())])  # mutable intermediate edge\n",
    "        activation_cell.add_edges_from([(2, 3, EdgeData().finalize())])  # immutable output edge\n",
    "\n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1)  # input\n",
    "        self.add_node(2)  # intermediate\n",
    "        self.add_node(3,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_1\").set_input([2]))  # activation cell 3\n",
    "        self.nodes[3]['subgraph'].name = \"activation_1\"\n",
    "\n",
    "        self.add_node(4)\n",
    "        self.add_node(5,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_2\").set_input([4]))  # activation cell 3\n",
    "        self.nodes[5]['subgraph'].name = \"activation_2\"\n",
    "\n",
    "        self.add_node(6)\n",
    "        self.add_node(7,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_3\").set_input([6]))  # activation cell 3\n",
    "        self.nodes[7]['subgraph'].name = \"activation_3\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (1, 2, EdgeData()),\n",
    "            (2, 3, EdgeData()),\n",
    "            (3, 4, EdgeData()),\n",
    "            (4, 5, EdgeData()),\n",
    "            (5, 6, EdgeData()),\n",
    "            (3, 6, EdgeData()),\n",
    "            (6, 7, EdgeData())\n",
    "        ])\n",
    "\n",
    "        self.edges[1, 2].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(3, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[3, 4].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[5, 6].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "\n",
    "        for scope in range(1, 4):\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_ops(edge),\n",
    "                scope=f\"activation_{scope}\",\n",
    "                private_edge_data=True,\n",
    "            )\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 16,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(7, 4, activation_cell, conv_option)\n",
    "        self._create_base_block(11, 6, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        \n",
    "        self._create_reduction_block(15, 8, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        \n",
    "        self._create_base_block(19, 10, activation_cell, conv_option)\n",
    "        self._create_base_block(23, 12, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        self._create_reduction_block(27, 14, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 64,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(31, 16, activation_cell, conv_option)\n",
    "        self._create_base_block(34, 18, activation_cell, conv_option)\n",
    "\n",
    "        # add head\n",
    "        self.add_node(39)\n",
    "        self.add_edges_from([\n",
    "            (38, 39, EdgeData())\n",
    "        ])\n",
    "        self.edges[38, 39].set('op',\n",
    "                               ops.Sequential(\n",
    "                                   nn.AvgPool2d(8),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64, 10),\n",
    "                                   nn.Softmax()\n",
    "                               ))  # convolutional edge\n",
    "        self.add_node(40)\n",
    "        self.add_edges_from([\n",
    "            (39, 40, EdgeData().finalize())\n",
    "        ])\n",
    "\n",
    "    def _create_base_block(self, start: int, stage: int, cell, conv_option: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "    def _create_reduction_block(self, start: int, stage: int, cell, conv_option_a: dict, conv_option_b: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),  # add conv\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "        conv_option_a[\"in_channels\"] = conv_option_a[\"out_channels\"]\n",
    "        conv_option_a[\"stride\"] = 1\n",
    "\n",
    "        self.edges[start, start + 3].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_b), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "    def _set_ops(self, edge):\n",
    "        edge.data.set('op', [\n",
    "            ops.Sequential(nn.ReLU()),\n",
    "            ops.Sequential(nn.Hardswish()),\n",
    "            ops.Sequential(nn.LeakyReLU()),\n",
    "            ops.Sequential(nn.Identity())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNResNet20SearchSpace(Graph):\n",
    "    \"\"\"\n",
    "    https://www.researchgate.net/figure/ResNet-20-architecture_fig3_351046093\n",
    "    \"\"\"\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        f\"activation_{i}\" for i in range(1, 20)\n",
    "    ]\n",
    "    \n",
    "    OPTIMIZER_SCOPE += [\n",
    "        \"u_stage_1\",\n",
    "        \"u_stage_2\",\n",
    "        \"u_stage_3\",\n",
    "        \"u_stage_4\",\n",
    "        \"b_stage_1\",\n",
    "        \"b_stage_2\"\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "         # unary cell definition\n",
    "        unary_cell = Graph()\n",
    "        unary_cell.name = 'u_cell'\n",
    "        unary_cell.add_node(1) # input node\n",
    "        unary_cell.add_node(2) # intermediate node\n",
    "        unary_cell.add_node(3) # output node\n",
    "        unary_cell.add_edges_from([(1, 2, EdgeData())]) # mutable edge\n",
    "        unary_cell.edges[1, 2].set('cell_name', 'u_cell')\n",
    "        unary_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable edge\n",
    "        \n",
    "        # binary cell definition\n",
    "        binary_cell = Graph()\n",
    "        binary_cell.name = 'b_cell'\n",
    "        binary_cell.add_node(1) # input node\n",
    "        binary_cell.add_node(2) # input node\n",
    "        binary_cell.add_node(3) # concatination node\n",
    "        binary_cell.nodes[3]['comb_op'] = stack()\n",
    "        binary_cell.add_node(4) # intermediate node\n",
    "        binary_cell.add_node(5) # output node\n",
    "        binary_cell.add_edges_from([(3, 4, EdgeData())]) # mutable edge\n",
    "        binary_cell.edges[3, 4].set('cell_name', 'b_cell') \n",
    "        binary_cell.add_edges_from([(1, 3, EdgeData().finalize()),\n",
    "                                    (2, 3, EdgeData().finalize()),\n",
    "                                    (4, 5, EdgeData().finalize())]) # immutable edges\n",
    "        \n",
    "        # activation cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'a_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2, subgraph=deepcopy(unary_cell).set_scope('u_stage_1').set_input([1])) # unary cell 1\n",
    "        activation_cell.nodes[2]['subgraph'].name = 'u_stage_1'\n",
    "        activation_cell.add_node(3, subgraph=deepcopy(unary_cell).set_scope('u_stage_2').set_input([1])) # unary cell 2\n",
    "        activation_cell.nodes[3]['subgraph'].name = 'u_stage_2'\n",
    "        activation_cell.add_node(4, subgraph=deepcopy(unary_cell).set_scope('u_stage_3').set_input([1])) # unary cell 3\n",
    "        activation_cell.nodes[4]['subgraph'].name = 'u_stage_3'\n",
    "        activation_cell.add_node(5, subgraph=deepcopy(binary_cell).set_scope('b_stage_1').set_input([2, 3])) # binary cell 1\n",
    "        activation_cell.nodes[5]['subgraph'].name = 'b_stage_1'\n",
    "        activation_cell.add_node(6, subgraph=deepcopy(unary_cell).set_scope('u_stage_4').set_input([5])) # unary cell 4\n",
    "        activation_cell.nodes[6]['subgraph'].name = 'u_stage_4'\n",
    "        activation_cell.add_node(7, subgraph=deepcopy(binary_cell).set_scope('b_stage_2').set_input([4, 6])) # binary cell 2\n",
    "        activation_cell.nodes[7]['subgraph'].name = 'b_stage_2'\n",
    "        activation_cell.add_node(8) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize()), \n",
    "                                        (1, 3, EdgeData().finalize()),\n",
    "                                        (1, 4, EdgeData().finalize()),\n",
    "                                        (2, 5, EdgeData().finalize()),\n",
    "                                        (3, 5, EdgeData().finalize()), \n",
    "                                        (4, 7, EdgeData().finalize()),\n",
    "                                        (5, 6, EdgeData().finalize()),\n",
    "                                        (6, 7, EdgeData().finalize()),\n",
    "                                        (7, 8, EdgeData().finalize())])\n",
    "\n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1)  # input\n",
    "        self.add_node(2)  # intermediate\n",
    "        self.add_node(3,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_1\").set_input([2]))  # activation cell 3\n",
    "        self.nodes[3]['subgraph'].name = \"activation_1\"\n",
    "\n",
    "        self.add_node(4)\n",
    "        self.add_node(5,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_2\").set_input([4]))  # activation cell 3\n",
    "        self.nodes[5]['subgraph'].name = \"activation_2\"\n",
    "\n",
    "        self.add_node(6)\n",
    "        self.add_node(7,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_3\").set_input([6]))  # activation cell 3\n",
    "        self.nodes[7]['subgraph'].name = \"activation_3\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (1, 2, EdgeData()),\n",
    "            (2, 3, EdgeData()),\n",
    "            (3, 4, EdgeData()),\n",
    "            (4, 5, EdgeData()),\n",
    "            (5, 6, EdgeData()),\n",
    "            (3, 6, EdgeData()),\n",
    "            (6, 7, EdgeData())\n",
    "        ])\n",
    "\n",
    "        self.edges[1, 2].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(3, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[3, 4].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[5, 6].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "\n",
    "        for scope in range(1, 4):\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_ops(edge),\n",
    "                scope=f\"activation_{scope}\",\n",
    "                private_edge_data=True,\n",
    "            )\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 16,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        \n",
    "        self._create_base_block(7, 4, activation_cell, conv_option)\n",
    "        self._create_base_block(11, 6, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        \n",
    "        self._create_reduction_block(15, 8, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        \n",
    "        self._create_base_block(19, 10, activation_cell, conv_option)\n",
    "        self._create_base_block(23, 12, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        self._create_reduction_block(27, 14, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 64,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(31, 16, activation_cell, conv_option)\n",
    "        self._create_base_block(34, 18, activation_cell, conv_option)\n",
    "\n",
    "        # add head\n",
    "        self.add_node(39)\n",
    "        self.add_edges_from([\n",
    "            (38, 39, EdgeData())\n",
    "        ])\n",
    "        self.edges[38, 39].set('op',\n",
    "                               ops.Sequential(\n",
    "                                   nn.AvgPool2d(8),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64, 10),\n",
    "                                   nn.Softmax()\n",
    "                               ))  # convolutional edge\n",
    "        self.add_node(40)\n",
    "        self.add_edges_from([\n",
    "            (39, 40, EdgeData().finalize())\n",
    "        ])\n",
    "\n",
    "    def _create_base_block(self, start: int, stage: int, cell, conv_option: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        \n",
    "    def _create_reduction_block(self, start: int, stage: int, cell, conv_option_a: dict, conv_option_b: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),  # add conv\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "        conv_option_a[\"in_channels\"] = conv_option_a[\"out_channels\"]\n",
    "        conv_option_a[\"stride\"] = 1\n",
    "\n",
    "        self.edges[start, start + 3].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_b), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "    def _set_ops(self, edge):\n",
    "        if edge.data['cell_name'] == 'u_cell':\n",
    "            edge.data.set('op', [\n",
    "                ops.Identity(), \n",
    "                ops.Zero(stride=1)\n",
    "            ]) \n",
    "        elif edge.data['cell_name'] == 'b_cell':\n",
    "            edge.data.set('op', [\n",
    "                Minimum(), \n",
    "                Maximum()\n",
    "            ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = RNNResNet20SearchSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 12:14:34 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mParsed graph:\n",
      "Graph activation_1:\n",
      " Graph(\n",
      "  (activation_1-edge(1,2)): Identity()\n",
      "  (activation_1-edge(1,3)): Identity()\n",
      "  (activation_1-edge(1,4)): Identity()\n",
      "  (activation_1-subgraph_at(2)): Graph u_stage_1-0.3843399, scope activation_1, 3 nodes\n",
      "  (activation_1-edge(2,5)): Identity()\n",
      "  (activation_1-subgraph_at(3)): Graph u_stage_2-0.1293691, scope activation_1, 3 nodes\n",
      "  (activation_1-edge(3,5)): Identity()\n",
      "  (activation_1-subgraph_at(4)): Graph u_stage_3-0.7785561, scope activation_1, 3 nodes\n",
      "  (activation_1-edge(4,7)): Identity()\n",
      "  (activation_1-subgraph_at(5)): Graph b_stage_1-0.4011927, scope activation_1, 5 nodes\n",
      "  (activation_1-edge(5,6)): Identity()\n",
      "  (activation_1-subgraph_at(6)): Graph u_stage_4-0.5002530, scope activation_1, 3 nodes\n",
      "  (activation_1-edge(6,7)): Identity()\n",
      "  (activation_1-subgraph_at(7)): Graph b_stage_2-0.4709687, scope activation_1, 5 nodes\n",
      "  (activation_1-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_10:\n",
      " Graph(\n",
      "  (activation_10-edge(1,2)): Identity()\n",
      "  (activation_10-edge(1,3)): Identity()\n",
      "  (activation_10-edge(1,4)): Identity()\n",
      "  (activation_10-subgraph_at(2)): Graph u_stage_1-0.0667787, scope activation_10, 3 nodes\n",
      "  (activation_10-edge(2,5)): Identity()\n",
      "  (activation_10-subgraph_at(3)): Graph u_stage_2-0.1771353, scope activation_10, 3 nodes\n",
      "  (activation_10-edge(3,5)): Identity()\n",
      "  (activation_10-subgraph_at(4)): Graph u_stage_3-0.2343009, scope activation_10, 3 nodes\n",
      "  (activation_10-edge(4,7)): Identity()\n",
      "  (activation_10-subgraph_at(5)): Graph b_stage_1-0.9283214, scope activation_10, 5 nodes\n",
      "  (activation_10-edge(5,6)): Identity()\n",
      "  (activation_10-subgraph_at(6)): Graph u_stage_4-0.3819291, scope activation_10, 3 nodes\n",
      "  (activation_10-edge(6,7)): Identity()\n",
      "  (activation_10-subgraph_at(7)): Graph b_stage_2-0.8073818, scope activation_10, 5 nodes\n",
      "  (activation_10-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_11:\n",
      " Graph(\n",
      "  (activation_11-edge(1,2)): Identity()\n",
      "  (activation_11-edge(1,3)): Identity()\n",
      "  (activation_11-edge(1,4)): Identity()\n",
      "  (activation_11-subgraph_at(2)): Graph u_stage_1-0.3812447, scope activation_11, 3 nodes\n",
      "  (activation_11-edge(2,5)): Identity()\n",
      "  (activation_11-subgraph_at(3)): Graph u_stage_2-0.7653481, scope activation_11, 3 nodes\n",
      "  (activation_11-edge(3,5)): Identity()\n",
      "  (activation_11-subgraph_at(4)): Graph u_stage_3-0.6157610, scope activation_11, 3 nodes\n",
      "  (activation_11-edge(4,7)): Identity()\n",
      "  (activation_11-subgraph_at(5)): Graph b_stage_1-0.2693177, scope activation_11, 5 nodes\n",
      "  (activation_11-edge(5,6)): Identity()\n",
      "  (activation_11-subgraph_at(6)): Graph u_stage_4-0.5828106, scope activation_11, 3 nodes\n",
      "  (activation_11-edge(6,7)): Identity()\n",
      "  (activation_11-subgraph_at(7)): Graph b_stage_2-0.7038528, scope activation_11, 5 nodes\n",
      "  (activation_11-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_12:\n",
      " Graph(\n",
      "  (activation_12-edge(1,2)): Identity()\n",
      "  (activation_12-edge(1,3)): Identity()\n",
      "  (activation_12-edge(1,4)): Identity()\n",
      "  (activation_12-subgraph_at(2)): Graph u_stage_1-0.6771791, scope activation_12, 3 nodes\n",
      "  (activation_12-edge(2,5)): Identity()\n",
      "  (activation_12-subgraph_at(3)): Graph u_stage_2-0.6407471, scope activation_12, 3 nodes\n",
      "  (activation_12-edge(3,5)): Identity()\n",
      "  (activation_12-subgraph_at(4)): Graph u_stage_3-0.5959023, scope activation_12, 3 nodes\n",
      "  (activation_12-edge(4,7)): Identity()\n",
      "  (activation_12-subgraph_at(5)): Graph b_stage_1-0.0920509, scope activation_12, 5 nodes\n",
      "  (activation_12-edge(5,6)): Identity()\n",
      "  (activation_12-subgraph_at(6)): Graph u_stage_4-0.9451891, scope activation_12, 3 nodes\n",
      "  (activation_12-edge(6,7)): Identity()\n",
      "  (activation_12-subgraph_at(7)): Graph b_stage_2-0.7148419, scope activation_12, 5 nodes\n",
      "  (activation_12-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_13:\n",
      " Graph(\n",
      "  (activation_13-edge(1,2)): Identity()\n",
      "  (activation_13-edge(1,3)): Identity()\n",
      "  (activation_13-edge(1,4)): Identity()\n",
      "  (activation_13-subgraph_at(2)): Graph u_stage_1-0.6923507, scope activation_13, 3 nodes\n",
      "  (activation_13-edge(2,5)): Identity()\n",
      "  (activation_13-subgraph_at(3)): Graph u_stage_2-0.6208174, scope activation_13, 3 nodes\n",
      "  (activation_13-edge(3,5)): Identity()\n",
      "  (activation_13-subgraph_at(4)): Graph u_stage_3-0.6588514, scope activation_13, 3 nodes\n",
      "  (activation_13-edge(4,7)): Identity()\n",
      "  (activation_13-subgraph_at(5)): Graph b_stage_1-0.3789090, scope activation_13, 5 nodes\n",
      "  (activation_13-edge(5,6)): Identity()\n",
      "  (activation_13-subgraph_at(6)): Graph u_stage_4-0.5731759, scope activation_13, 3 nodes\n",
      "  (activation_13-edge(6,7)): Identity()\n",
      "  (activation_13-subgraph_at(7)): Graph b_stage_2-0.6600272, scope activation_13, 5 nodes\n",
      "  (activation_13-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_14:\n",
      " Graph(\n",
      "  (activation_14-edge(1,2)): Identity()\n",
      "  (activation_14-edge(1,3)): Identity()\n",
      "  (activation_14-edge(1,4)): Identity()\n",
      "  (activation_14-subgraph_at(2)): Graph u_stage_1-0.5080122, scope activation_14, 3 nodes\n",
      "  (activation_14-edge(2,5)): Identity()\n",
      "  (activation_14-subgraph_at(3)): Graph u_stage_2-0.1203417, scope activation_14, 3 nodes\n",
      "  (activation_14-edge(3,5)): Identity()\n",
      "  (activation_14-subgraph_at(4)): Graph u_stage_3-0.1055305, scope activation_14, 3 nodes\n",
      "  (activation_14-edge(4,7)): Identity()\n",
      "  (activation_14-subgraph_at(5)): Graph b_stage_1-0.9110606, scope activation_14, 5 nodes\n",
      "  (activation_14-edge(5,6)): Identity()\n",
      "  (activation_14-subgraph_at(6)): Graph u_stage_4-0.1245472, scope activation_14, 3 nodes\n",
      "  (activation_14-edge(6,7)): Identity()\n",
      "  (activation_14-subgraph_at(7)): Graph b_stage_2-0.8932670, scope activation_14, 5 nodes\n",
      "  (activation_14-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_15:\n",
      " Graph(\n",
      "  (activation_15-edge(1,2)): Identity()\n",
      "  (activation_15-edge(1,3)): Identity()\n",
      "  (activation_15-edge(1,4)): Identity()\n",
      "  (activation_15-subgraph_at(2)): Graph u_stage_1-0.4549026, scope activation_15, 3 nodes\n",
      "  (activation_15-edge(2,5)): Identity()\n",
      "  (activation_15-subgraph_at(3)): Graph u_stage_2-0.3398153, scope activation_15, 3 nodes\n",
      "  (activation_15-edge(3,5)): Identity()\n",
      "  (activation_15-subgraph_at(4)): Graph u_stage_3-0.4162177, scope activation_15, 3 nodes\n",
      "  (activation_15-edge(4,7)): Identity()\n",
      "  (activation_15-subgraph_at(5)): Graph b_stage_1-0.3772324, scope activation_15, 5 nodes\n",
      "  (activation_15-edge(5,6)): Identity()\n",
      "  (activation_15-subgraph_at(6)): Graph u_stage_4-0.5649829, scope activation_15, 3 nodes\n",
      "  (activation_15-edge(6,7)): Identity()\n",
      "  (activation_15-subgraph_at(7)): Graph b_stage_2-0.3355933, scope activation_15, 5 nodes\n",
      "  (activation_15-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_16:\n",
      " Graph(\n",
      "  (activation_16-edge(1,2)): Identity()\n",
      "  (activation_16-edge(1,3)): Identity()\n",
      "  (activation_16-edge(1,4)): Identity()\n",
      "  (activation_16-subgraph_at(2)): Graph u_stage_1-0.2335618, scope activation_16, 3 nodes\n",
      "  (activation_16-edge(2,5)): Identity()\n",
      "  (activation_16-subgraph_at(3)): Graph u_stage_2-0.2484701, scope activation_16, 3 nodes\n",
      "  (activation_16-edge(3,5)): Identity()\n",
      "  (activation_16-subgraph_at(4)): Graph u_stage_3-0.4805515, scope activation_16, 3 nodes\n",
      "  (activation_16-edge(4,7)): Identity()\n",
      "  (activation_16-subgraph_at(5)): Graph b_stage_1-0.9350813, scope activation_16, 5 nodes\n",
      "  (activation_16-edge(5,6)): Identity()\n",
      "  (activation_16-subgraph_at(6)): Graph u_stage_4-0.0239157, scope activation_16, 3 nodes\n",
      "  (activation_16-edge(6,7)): Identity()\n",
      "  (activation_16-subgraph_at(7)): Graph b_stage_2-0.7234136, scope activation_16, 5 nodes\n",
      "  (activation_16-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_17:\n",
      " Graph(\n",
      "  (activation_17-edge(1,2)): Identity()\n",
      "  (activation_17-edge(1,3)): Identity()\n",
      "  (activation_17-edge(1,4)): Identity()\n",
      "  (activation_17-subgraph_at(2)): Graph u_stage_1-0.4048602, scope activation_17, 3 nodes\n",
      "  (activation_17-edge(2,5)): Identity()\n",
      "  (activation_17-subgraph_at(3)): Graph u_stage_2-0.7642072, scope activation_17, 3 nodes\n",
      "  (activation_17-edge(3,5)): Identity()\n",
      "  (activation_17-subgraph_at(4)): Graph u_stage_3-0.4460791, scope activation_17, 3 nodes\n",
      "  (activation_17-edge(4,7)): Identity()\n",
      "  (activation_17-subgraph_at(5)): Graph b_stage_1-0.4294889, scope activation_17, 5 nodes\n",
      "  (activation_17-edge(5,6)): Identity()\n",
      "  (activation_17-subgraph_at(6)): Graph u_stage_4-0.2532168, scope activation_17, 3 nodes\n",
      "  (activation_17-edge(6,7)): Identity()\n",
      "  (activation_17-subgraph_at(7)): Graph b_stage_2-0.4750956, scope activation_17, 5 nodes\n",
      "  (activation_17-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_18:\n",
      " Graph(\n",
      "  (activation_18-edge(1,2)): Identity()\n",
      "  (activation_18-edge(1,3)): Identity()\n",
      "  (activation_18-edge(1,4)): Identity()\n",
      "  (activation_18-subgraph_at(2)): Graph u_stage_1-0.2835213, scope activation_18, 3 nodes\n",
      "  (activation_18-edge(2,5)): Identity()\n",
      "  (activation_18-subgraph_at(3)): Graph u_stage_2-0.6532936, scope activation_18, 3 nodes\n",
      "  (activation_18-edge(3,5)): Identity()\n",
      "  (activation_18-subgraph_at(4)): Graph u_stage_3-0.5994471, scope activation_18, 3 nodes\n",
      "  (activation_18-edge(4,7)): Identity()\n",
      "  (activation_18-subgraph_at(5)): Graph b_stage_1-0.9295455, scope activation_18, 5 nodes\n",
      "  (activation_18-edge(5,6)): Identity()\n",
      "  (activation_18-subgraph_at(6)): Graph u_stage_4-0.9688691, scope activation_18, 3 nodes\n",
      "  (activation_18-edge(6,7)): Identity()\n",
      "  (activation_18-subgraph_at(7)): Graph b_stage_2-0.5223802, scope activation_18, 5 nodes\n",
      "  (activation_18-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_19:\n",
      " Graph(\n",
      "  (activation_19-edge(1,2)): Identity()\n",
      "  (activation_19-edge(1,3)): Identity()\n",
      "  (activation_19-edge(1,4)): Identity()\n",
      "  (activation_19-subgraph_at(2)): Graph u_stage_1-0.2999031, scope activation_19, 3 nodes\n",
      "  (activation_19-edge(2,5)): Identity()\n",
      "  (activation_19-subgraph_at(3)): Graph u_stage_2-0.5178049, scope activation_19, 3 nodes\n",
      "  (activation_19-edge(3,5)): Identity()\n",
      "  (activation_19-subgraph_at(4)): Graph u_stage_3-0.6731629, scope activation_19, 3 nodes\n",
      "  (activation_19-edge(4,7)): Identity()\n",
      "  (activation_19-subgraph_at(5)): Graph b_stage_1-0.9461972, scope activation_19, 5 nodes\n",
      "  (activation_19-edge(5,6)): Identity()\n",
      "  (activation_19-subgraph_at(6)): Graph u_stage_4-0.1551074, scope activation_19, 3 nodes\n",
      "  (activation_19-edge(6,7)): Identity()\n",
      "  (activation_19-subgraph_at(7)): Graph b_stage_2-0.0366847, scope activation_19, 5 nodes\n",
      "  (activation_19-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_2:\n",
      " Graph(\n",
      "  (activation_2-edge(1,2)): Identity()\n",
      "  (activation_2-edge(1,3)): Identity()\n",
      "  (activation_2-edge(1,4)): Identity()\n",
      "  (activation_2-subgraph_at(2)): Graph u_stage_1-0.3739384, scope activation_2, 3 nodes\n",
      "  (activation_2-edge(2,5)): Identity()\n",
      "  (activation_2-subgraph_at(3)): Graph u_stage_2-0.9158613, scope activation_2, 3 nodes\n",
      "  (activation_2-edge(3,5)): Identity()\n",
      "  (activation_2-subgraph_at(4)): Graph u_stage_3-0.4319223, scope activation_2, 3 nodes\n",
      "  (activation_2-edge(4,7)): Identity()\n",
      "  (activation_2-subgraph_at(5)): Graph b_stage_1-0.3592140, scope activation_2, 5 nodes\n",
      "  (activation_2-edge(5,6)): Identity()\n",
      "  (activation_2-subgraph_at(6)): Graph u_stage_4-0.4008781, scope activation_2, 3 nodes\n",
      "  (activation_2-edge(6,7)): Identity()\n",
      "  (activation_2-subgraph_at(7)): Graph b_stage_2-0.7662957, scope activation_2, 5 nodes\n",
      "  (activation_2-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_3:\n",
      " Graph(\n",
      "  (activation_3-edge(1,2)): Identity()\n",
      "  (activation_3-edge(1,3)): Identity()\n",
      "  (activation_3-edge(1,4)): Identity()\n",
      "  (activation_3-subgraph_at(2)): Graph u_stage_1-0.8665146, scope activation_3, 3 nodes\n",
      "  (activation_3-edge(2,5)): Identity()\n",
      "  (activation_3-subgraph_at(3)): Graph u_stage_2-0.4797275, scope activation_3, 3 nodes\n",
      "  (activation_3-edge(3,5)): Identity()\n",
      "  (activation_3-subgraph_at(4)): Graph u_stage_3-0.2913593, scope activation_3, 3 nodes\n",
      "  (activation_3-edge(4,7)): Identity()\n",
      "  (activation_3-subgraph_at(5)): Graph b_stage_1-0.4459871, scope activation_3, 5 nodes\n",
      "  (activation_3-edge(5,6)): Identity()\n",
      "  (activation_3-subgraph_at(6)): Graph u_stage_4-0.3440156, scope activation_3, 3 nodes\n",
      "  (activation_3-edge(6,7)): Identity()\n",
      "  (activation_3-subgraph_at(7)): Graph b_stage_2-0.2435321, scope activation_3, 5 nodes\n",
      "  (activation_3-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_4:\n",
      " Graph(\n",
      "  (activation_4-edge(1,2)): Identity()\n",
      "  (activation_4-edge(1,3)): Identity()\n",
      "  (activation_4-edge(1,4)): Identity()\n",
      "  (activation_4-subgraph_at(2)): Graph u_stage_1-0.9558757, scope activation_4, 3 nodes\n",
      "  (activation_4-edge(2,5)): Identity()\n",
      "  (activation_4-subgraph_at(3)): Graph u_stage_2-0.4993052, scope activation_4, 3 nodes\n",
      "  (activation_4-edge(3,5)): Identity()\n",
      "  (activation_4-subgraph_at(4)): Graph u_stage_3-0.1099749, scope activation_4, 3 nodes\n",
      "  (activation_4-edge(4,7)): Identity()\n",
      "  (activation_4-subgraph_at(5)): Graph b_stage_1-0.3839066, scope activation_4, 5 nodes\n",
      "  (activation_4-edge(5,6)): Identity()\n",
      "  (activation_4-subgraph_at(6)): Graph u_stage_4-0.3887169, scope activation_4, 3 nodes\n",
      "  (activation_4-edge(6,7)): Identity()\n",
      "  (activation_4-subgraph_at(7)): Graph b_stage_2-0.5135345, scope activation_4, 5 nodes\n",
      "  (activation_4-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_5:\n",
      " Graph(\n",
      "  (activation_5-edge(1,2)): Identity()\n",
      "  (activation_5-edge(1,3)): Identity()\n",
      "  (activation_5-edge(1,4)): Identity()\n",
      "  (activation_5-subgraph_at(2)): Graph u_stage_1-0.9766335, scope activation_5, 3 nodes\n",
      "  (activation_5-edge(2,5)): Identity()\n",
      "  (activation_5-subgraph_at(3)): Graph u_stage_2-0.5658941, scope activation_5, 3 nodes\n",
      "  (activation_5-edge(3,5)): Identity()\n",
      "  (activation_5-subgraph_at(4)): Graph u_stage_3-0.6180915, scope activation_5, 3 nodes\n",
      "  (activation_5-edge(4,7)): Identity()\n",
      "  (activation_5-subgraph_at(5)): Graph b_stage_1-0.6756291, scope activation_5, 5 nodes\n",
      "  (activation_5-edge(5,6)): Identity()\n",
      "  (activation_5-subgraph_at(6)): Graph u_stage_4-0.5022222, scope activation_5, 3 nodes\n",
      "  (activation_5-edge(6,7)): Identity()\n",
      "  (activation_5-subgraph_at(7)): Graph b_stage_2-0.4866781, scope activation_5, 5 nodes\n",
      "  (activation_5-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_6:\n",
      " Graph(\n",
      "  (activation_6-edge(1,2)): Identity()\n",
      "  (activation_6-edge(1,3)): Identity()\n",
      "  (activation_6-edge(1,4)): Identity()\n",
      "  (activation_6-subgraph_at(2)): Graph u_stage_1-0.6839217, scope activation_6, 3 nodes\n",
      "  (activation_6-edge(2,5)): Identity()\n",
      "  (activation_6-subgraph_at(3)): Graph u_stage_2-0.0918953, scope activation_6, 3 nodes\n",
      "  (activation_6-edge(3,5)): Identity()\n",
      "  (activation_6-subgraph_at(4)): Graph u_stage_3-0.3171452, scope activation_6, 3 nodes\n",
      "  (activation_6-edge(4,7)): Identity()\n",
      "  (activation_6-subgraph_at(5)): Graph b_stage_1-0.8909786, scope activation_6, 5 nodes\n",
      "  (activation_6-edge(5,6)): Identity()\n",
      "  (activation_6-subgraph_at(6)): Graph u_stage_4-0.2273782, scope activation_6, 3 nodes\n",
      "  (activation_6-edge(6,7)): Identity()\n",
      "  (activation_6-subgraph_at(7)): Graph b_stage_2-0.9675824, scope activation_6, 5 nodes\n",
      "  (activation_6-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_7:\n",
      " Graph(\n",
      "  (activation_7-edge(1,2)): Identity()\n",
      "  (activation_7-edge(1,3)): Identity()\n",
      "  (activation_7-edge(1,4)): Identity()\n",
      "  (activation_7-subgraph_at(2)): Graph u_stage_1-0.5753827, scope activation_7, 3 nodes\n",
      "  (activation_7-edge(2,5)): Identity()\n",
      "  (activation_7-subgraph_at(3)): Graph u_stage_2-0.0404360, scope activation_7, 3 nodes\n",
      "  (activation_7-edge(3,5)): Identity()\n",
      "  (activation_7-subgraph_at(4)): Graph u_stage_3-0.0934782, scope activation_7, 3 nodes\n",
      "  (activation_7-edge(4,7)): Identity()\n",
      "  (activation_7-subgraph_at(5)): Graph b_stage_1-0.2003016, scope activation_7, 5 nodes\n",
      "  (activation_7-edge(5,6)): Identity()\n",
      "  (activation_7-subgraph_at(6)): Graph u_stage_4-0.3268116, scope activation_7, 3 nodes\n",
      "  (activation_7-edge(6,7)): Identity()\n",
      "  (activation_7-subgraph_at(7)): Graph b_stage_2-0.1131082, scope activation_7, 5 nodes\n",
      "  (activation_7-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_8:\n",
      " Graph(\n",
      "  (activation_8-edge(1,2)): Identity()\n",
      "  (activation_8-edge(1,3)): Identity()\n",
      "  (activation_8-edge(1,4)): Identity()\n",
      "  (activation_8-subgraph_at(2)): Graph u_stage_1-0.3641546, scope activation_8, 3 nodes\n",
      "  (activation_8-edge(2,5)): Identity()\n",
      "  (activation_8-subgraph_at(3)): Graph u_stage_2-0.2337337, scope activation_8, 3 nodes\n",
      "  (activation_8-edge(3,5)): Identity()\n",
      "  (activation_8-subgraph_at(4)): Graph u_stage_3-0.0436939, scope activation_8, 3 nodes\n",
      "  (activation_8-edge(4,7)): Identity()\n",
      "  (activation_8-subgraph_at(5)): Graph b_stage_1-0.3826719, scope activation_8, 5 nodes\n",
      "  (activation_8-edge(5,6)): Identity()\n",
      "  (activation_8-subgraph_at(6)): Graph u_stage_4-0.0045067, scope activation_8, 3 nodes\n",
      "  (activation_8-edge(6,7)): Identity()\n",
      "  (activation_8-subgraph_at(7)): Graph b_stage_2-0.1164915, scope activation_8, 5 nodes\n",
      "  (activation_8-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph activation_9:\n",
      " Graph(\n",
      "  (activation_9-edge(1,2)): Identity()\n",
      "  (activation_9-edge(1,3)): Identity()\n",
      "  (activation_9-edge(1,4)): Identity()\n",
      "  (activation_9-subgraph_at(2)): Graph u_stage_1-0.9349454, scope activation_9, 3 nodes\n",
      "  (activation_9-edge(2,5)): Identity()\n",
      "  (activation_9-subgraph_at(3)): Graph u_stage_2-0.1993659, scope activation_9, 3 nodes\n",
      "  (activation_9-edge(3,5)): Identity()\n",
      "  (activation_9-subgraph_at(4)): Graph u_stage_3-0.7410612, scope activation_9, 3 nodes\n",
      "  (activation_9-edge(4,7)): Identity()\n",
      "  (activation_9-subgraph_at(5)): Graph b_stage_1-0.1977055, scope activation_9, 5 nodes\n",
      "  (activation_9-edge(5,6)): Identity()\n",
      "  (activation_9-subgraph_at(6)): Graph u_stage_4-0.0014952, scope activation_9, 3 nodes\n",
      "  (activation_9-edge(6,7)): Identity()\n",
      "  (activation_9-subgraph_at(7)): Graph b_stage_2-0.8965380, scope activation_9, 5 nodes\n",
      "  (activation_9-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph b_stage_1:\n",
      " Graph(\n",
      "  (b_stage_1-edge(1,3)): Identity()\n",
      "  (b_stage_1-edge(2,3)): Identity()\n",
      "  (b_stage_1-edge(3,4)): MixedOp(\n",
      "    (primitive-0): Minimum()\n",
      "    (primitive-1): Maximum()\n",
      "  )\n",
      "  (b_stage_1-edge(4,5)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph b_stage_2:\n",
      " Graph(\n",
      "  (b_stage_2-edge(1,3)): Identity()\n",
      "  (b_stage_2-edge(2,3)): Identity()\n",
      "  (b_stage_2-edge(3,4)): MixedOp(\n",
      "    (primitive-0): Minimum()\n",
      "    (primitive-1): Maximum()\n",
      "  )\n",
      "  (b_stage_2-edge(4,5)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_1:\n",
      " Graph(\n",
      "  (u_stage_1-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "  )\n",
      "  (u_stage_1-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_2:\n",
      " Graph(\n",
      "  (u_stage_2-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "  )\n",
      "  (u_stage_2-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_3:\n",
      " Graph(\n",
      "  (u_stage_3-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "  )\n",
      "  (u_stage_3-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_4:\n",
      " Graph(\n",
      "  (u_stage_4-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "  )\n",
      "  (u_stage_4-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph makrograph:\n",
      " RNNResNet20SearchSpace(\n",
      "  (makrograph-edge(1,2)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(2,3)): Identity()\n",
      "  (makrograph-subgraph_at(3)): Graph activation_1-0.3591680, scope activation_1, 8 nodes\n",
      "  (makrograph-edge(3,4)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(3,6)): Identity()\n",
      "  (makrograph-edge(4,5)): Identity()\n",
      "  (makrograph-subgraph_at(5)): Graph activation_2-0.6561818, scope activation_2, 8 nodes\n",
      "  (makrograph-edge(5,6)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(6,7)): Identity()\n",
      "  (makrograph-subgraph_at(7)): Graph activation_3-0.9930566, scope activation_3, 8 nodes\n",
      "  (makrograph-edge(7,8)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(7,10)): Identity()\n",
      "  (makrograph-edge(8,9)): Identity()\n",
      "  (makrograph-subgraph_at(9)): Graph activation_4-0.1869409, scope activation_4, 8 nodes\n",
      "  (makrograph-edge(9,10)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(10,11)): Identity()\n",
      "  (makrograph-subgraph_at(11)): Graph activation_5-0.9800413, scope activation_5, 8 nodes\n",
      "  (makrograph-edge(11,12)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(11,14)): Identity()\n",
      "  (makrograph-edge(12,13)): Identity()\n",
      "  (makrograph-subgraph_at(13)): Graph activation_6-0.3145239, scope activation_6, 8 nodes\n",
      "  (makrograph-edge(13,14)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(14,15)): Identity()\n",
      "  (makrograph-subgraph_at(15)): Graph activation_7-0.9841697, scope activation_7, 8 nodes\n",
      "  (makrograph-edge(15,16)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(15,18)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(16,17)): Identity()\n",
      "  (makrograph-subgraph_at(17)): Graph activation_8-0.7972108, scope activation_8, 8 nodes\n",
      "  (makrograph-edge(17,18)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(18,19)): Identity()\n",
      "  (makrograph-subgraph_at(19)): Graph activation_9-0.6046455, scope activation_9, 8 nodes\n",
      "  (makrograph-edge(19,20)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(19,22)): Identity()\n",
      "  (makrograph-edge(20,21)): Identity()\n",
      "  (makrograph-subgraph_at(21)): Graph activation_10-0.8461087, scope activation_10, 8 nodes\n",
      "  (makrograph-edge(21,22)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(22,23)): Identity()\n",
      "  (makrograph-subgraph_at(23)): Graph activation_11-0.4358135, scope activation_11, 8 nodes\n",
      "  (makrograph-edge(23,24)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(23,26)): Identity()\n",
      "  (makrograph-edge(24,25)): Identity()\n",
      "  (makrograph-subgraph_at(25)): Graph activation_12-0.8270781, scope activation_12, 8 nodes\n",
      "  (makrograph-edge(25,26)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(26,27)): Identity()\n",
      "  (makrograph-subgraph_at(27)): Graph activation_13-0.2728711, scope activation_13, 8 nodes\n",
      "  (makrograph-edge(27,28)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(27,30)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(28,29)): Identity()\n",
      "  (makrograph-subgraph_at(29)): Graph activation_14-0.2016561, scope activation_14, 8 nodes\n",
      "  (makrograph-edge(29,30)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(30,31)): Identity()\n",
      "  (makrograph-subgraph_at(31)): Graph activation_15-0.4697992, scope activation_15, 8 nodes\n",
      "  (makrograph-edge(31,32)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(31,34)): Identity()\n",
      "  (makrograph-edge(32,33)): Identity()\n",
      "  (makrograph-subgraph_at(33)): Graph activation_16-0.8219759, scope activation_16, 8 nodes\n",
      "  (makrograph-edge(33,34)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(34,35)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(34,37)): Identity()\n",
      "  (makrograph-subgraph_at(35)): Graph activation_17-0.0060066, scope activation_17, 8 nodes\n",
      "  (makrograph-edge(35,36)): Identity()\n",
      "  (makrograph-subgraph_at(36)): Graph activation_18-0.2282595, scope activation_18, 8 nodes\n",
      "  (makrograph-edge(36,37)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(37,38)): Identity()\n",
      "  (makrograph-subgraph_at(38)): Graph activation_19-0.0875565, scope activation_19, 8 nodes\n",
      "  (makrograph-edge(38,39)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "      (3): Softmax(dim=None)\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(39,40)): Identity()\n",
      ")\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = DARTSOptimizer(config)\n",
    "optimizer.adapt_search_space(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/05 12:14:57 nl.defaults.trainer]: \u001b[0mparam size = 0.271690MB\n",
      "\u001b[32m[07/05 12:14:57 nl.defaults.trainer]: \u001b[0mStart training\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[07/05 12:14:58 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mArch weights (alphas, last column argmax): \n",
      "-0.001503, -0.001294, 1\n",
      "-0.000532, +0.000716, 1\n",
      "-0.001191, -0.000102, 1\n",
      "+0.001855, -0.000155, 0\n",
      "+0.001110, +0.000305, 0\n",
      "-0.000550, +0.000301, 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2562033/2031152707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/defaults/trainer.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, resume_from)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mdata_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mlogits_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/optimizers/oneshot/darts/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, data_train, data_val)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# Update architecture weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mlogits_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/search_spaces/core/graph.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;31m# TODO: merge 'subgraph' and 'comb_op'. It is basicallly the same thing. Also in parse()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'subgraph'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subgraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/search_spaces/core/graph.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;31m# TODO: merge 'subgraph' and 'comb_op'. It is basicallly the same thing. Also in parse()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'subgraph'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subgraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/search_spaces/core/graph.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# Assign x to the corresponding input nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_x_to_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlexicographical_topological_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/search_spaces/core/graph.py\u001b[0m in \u001b[0;36m_assign_x_to_nodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Expecting node 1 to be the parent.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m'subgraph'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Expecting node 1 not to have a subgraph as it serves as input node.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(optimizer, config)\n",
    "trainer.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate_oneshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASLib Project",
   "language": "python",
   "name": "naslib_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
