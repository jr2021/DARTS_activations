{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from naslib.defaults.trainer import Trainer\n",
    "from naslib.optimizers import DARTSOptimizer\n",
    "from naslib.search_spaces import DartsSearchSpace\n",
    "from naslib.utils import utils, setup_logger, get_config_from_args, set_seed, log_args\n",
    "from naslib.search_spaces.core.graph import Graph, EdgeData\n",
    "from naslib.search_spaces.core import primitives as ops\n",
    "from torch import nn\n",
    "from fvcore.common.config import CfgNode\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from naslib.search_spaces.core.primitives import AbstractPrimitive\n",
    "from activation_sub_func.binary_func import *\n",
    "from activation_sub_func.unary_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mdataset....................................cifar10\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mseed.............................................0\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0msearch_space...........................nasbench201\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mout_dir........................................run\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0moptimizer....................................darts\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0msearchacq_fn_optimization: random_sampling\n",
      "acq_fn_type: its\n",
      "arch_learning_rate: 3e-06\n",
      "arch_weight_decay: 0.001\n",
      "batch_size: 16\n",
      "checkpoint_freq: 1000\n",
      "cutout: False\n",
      "cutout_length: 16\n",
      "cutout_prob: 1.0\n",
      "data_size: 25000\n",
      "debug_predictor: False\n",
      "drop_path_prob: 0.0\n",
      "encoding_type: adjacency_one_hot\n",
      "epochs: 100\n",
      "fidelity: -1\n",
      "gpu: None\n",
      "grad_clip: 5\n",
      "k: 10\n",
      "learning_rate: 2e-05\n",
      "learning_rate_min: 0.001\n",
      "max_mutations: 1\n",
      "momentum: 0.9\n",
      "num_arches_to_mutate: 2\n",
      "num_candidates: 20\n",
      "num_ensemble: 3\n",
      "num_init: 10\n",
      "output_weights: True\n",
      "population_size: 30\n",
      "predictor_type: var_sparse_gp\n",
      "sample_size: 10\n",
      "seed: 0\n",
      "tau_max: 10\n",
      "tau_min: 0.1\n",
      "train_portion: 0.7\n",
      "unrolled: False\n",
      "warm_start_epochs: 0\n",
      "weight_decay: 0.0003\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mevaluationauxiliary_weight: 0.4\n",
      "batch_size: 96\n",
      "checkpoint_freq: 30\n",
      "cutout: True\n",
      "cutout_length: 16\n",
      "cutout_prob: 1.0\n",
      "data_size: 50000\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://127.0.0.1:8888\n",
      "drop_path_prob: 0.2\n",
      "epochs: 600\n",
      "gpu: None\n",
      "grad_clip: 5\n",
      "learning_rate: 0.025\n",
      "learning_rate_min: 0.0\n",
      "momentum: 0.9\n",
      "multiprocessing_distributed: False\n",
      "rank: 0\n",
      "train_portion: 1.0\n",
      "warm_start_epochs: 0\n",
      "weight_decay: 0.0003\n",
      "world_size: 1\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0meval_only....................................False\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mresume.......................................False\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mmodel_path....................................None\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mgpu...........................................None\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0msave.........................run/cifar10/bananas/0\n",
      "\u001b[32m[07/14 18:52:57 nl.utils.utils]: \u001b[0mdata../project/dl2022s/robertsj/NASLib/naslib/data\n"
     ]
    }
   ],
   "source": [
    "config = utils.get_config_from_args(config_type='nas')\n",
    "config.optimizer = 'darts' # 'gdas', 'drnas'\n",
    "config.search.batch_size = 16\n",
    "config.search.learning_rate = 0.00002\n",
    "config.search.arch_learning_rate = 0.000003\n",
    "utils.set_seed(config.seed)\n",
    "clear_output(wait=True)\n",
    "utils.log_args(config)\n",
    "\n",
    "logger = setup_logger(config.save + '/log.log')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'activation_1'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'activation_cell'\n",
    "        activation_cell.add_node(1)  # input node\n",
    "        activation_cell.add_node(2)  # unary node / intermediate node\n",
    "        activation_cell.add_node(3)  # unary node / intermediate node\n",
    "        activation_cell.add_node(4)  # binary node / output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData())])  # mutable intermediate edge\n",
    "        activation_cell.edges[1, 2].set('cell_name', 'activation_cell')\n",
    "        activation_cell.add_edges_from([(1, 3, EdgeData())])  # mutable intermediate edge\n",
    "        activation_cell.edges[1, 3].set('cell_name', 'activation_cell')\n",
    "\n",
    "        activation_cell.add_edges_from([(2, 4, EdgeData().finalize())])  # mutable intermediate edge\n",
    "        activation_cell.add_edges_from([(3, 4, EdgeData().finalize())])  # mutable intermediate edge\n",
    "        activation_cell.nodes[4]['comb_op'] = Stack()\n",
    "\n",
    "        activation_cell.add_node(5)  # binary node\n",
    "        activation_cell.add_edges_from([(4, 5, EdgeData())])  # mutable intermediate edge\n",
    "        activation_cell.edges[4, 5].set('cell_name', 'activation_cell')\n",
    "        \n",
    "        activation_cell.add_node(6)\n",
    "        activation_cell.add_edges_from([(5, 6, EdgeData().finalize())])\n",
    "        \n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        self.add_node(3, subgraph=activation_cell.copy().set_scope('activation_1').set_input([2])) # activation cell\n",
    "        self.nodes[3]['subgraph'].name = 'activation_1'\n",
    "        self.add_node(4) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 4)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[3, 4].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge),\n",
    "            scope='activation_1',\n",
    "            private_edge_data=True,\n",
    "        )\n",
    "\n",
    "    def _set_ops(self, edge, channels=32):\n",
    "        # unary\n",
    "        if (edge.head, edge.tail) in {(1, 2), (1, 3)}:\n",
    "            edge.data.set(\"op\", [\n",
    "                ops.Identity(),\n",
    "                ops.Zero(stride=1),\n",
    "#                 Power(2),\n",
    "#                 Power(3),\n",
    "                Sqrt(),\n",
    "#                 Sin(),\n",
    "#                 Cos(),\n",
    "                Abs_op(),\n",
    "                Sign(),\n",
    "#                 Beta_mul(channels=channels),\n",
    "#                 Beta_add(channels=channels),\n",
    "                Log(),\n",
    "#                 Exp(),\n",
    "#                 Sinh(),\n",
    "#                 Cosh(),\n",
    "                Tanh(),\n",
    "                Asinh(),\n",
    "                Atan(),\n",
    "                Sinc(),\n",
    "                Maximum0(),\n",
    "                Minimum0(),\n",
    "                Sigmoid(),\n",
    "#                 LogExp(),\n",
    "#                 Exp2(),\n",
    "                Erf(),\n",
    "#                 Beta(channels=channels),\n",
    "            ])\n",
    "        # binary\n",
    "        elif (edge.head, edge.tail) in {(4, 5)}:\n",
    "            edge.data.set(\"op\", [\n",
    "                Add(),\n",
    "                Sub(),\n",
    "                Mul(),\n",
    "                Div(),\n",
    "                Maximum(),\n",
    "                Minimum(),\n",
    "                SigMul(),\n",
    "#                 ExpBetaSub2(channels=channels),\n",
    "#                 ExpBetaSubAbs(channels=channels),\n",
    "#                 BetaMix(channels=channels),\n",
    "            ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet20SearchSpace(Graph):\n",
    "    \"\"\"\n",
    "    https://www.researchgate.net/figure/ResNet-20-architecture_fig3_351046093\n",
    "    \"\"\"\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        f\"activation_{i}\" for i in range(1, 20)\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # cell definition\n",
    "#         activation_cell = Graph()\n",
    "#         activation_cell.name = 'activation_cell'\n",
    "#         activation_cell.add_node(1)  # input node\n",
    "#         activation_cell.add_node(2)  # unary node / intermediate node\n",
    "#         activation_cell.add_node(3)  # unary node / intermediate node\n",
    "#         activation_cell.add_node(4)  # binary node / output node\n",
    "#         activation_cell.add_edges_from([(1, 2, EdgeData())])  # mutable intermediate edge\n",
    "#         activation_cell.edges[1, 2].set('cell_name', 'activation_cell')\n",
    "#         activation_cell.add_edges_from([(1, 3, EdgeData())])  # mutable intermediate edge\n",
    "#         activation_cell.edges[1, 3].set('cell_name', 'activation_cell')\n",
    "\n",
    "#         activation_cell.add_edges_from([(2, 4, EdgeData().finalize())])  # mutable intermediate edge\n",
    "#         activation_cell.add_edges_from([(3, 4, EdgeData().finalize())])  # mutable intermediate edge\n",
    "#         activation_cell.nodes[4]['comb_op'] = Stack()\n",
    "\n",
    "#         activation_cell.add_node(5)  # binary node\n",
    "#         activation_cell.add_edges_from([(4, 5, EdgeData())])  # mutable intermediate edge\n",
    "#         activation_cell.edges[4, 5].set('cell_name', 'activation_cell')\n",
    "        \n",
    "#         activation_cell.add_node(6)\n",
    "#         activation_cell.add_edges_from([(5, 6, EdgeData().finalize())])\n",
    "\n",
    "          # linear activation (testing)\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'activation_cell'\n",
    "        activation_cell.add_node(1)  # input node\n",
    "        activation_cell.add_node(2)  # unary node / intermediate node\n",
    "        activation_cell.add_node(3)  # unary node / intermediate node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize())])  # immutable intermediate edge\n",
    "        activation_cell.add_edges_from([(2, 3, EdgeData())])  # immutable intermediate edge\n",
    "\n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1)  # input\n",
    "        self.add_node(2)  # intermediate\n",
    "        self.add_node(3,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_1\").set_input([2]))  # activation cell 3\n",
    "        self.nodes[3]['subgraph'].name = \"activation_1\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, 16),\n",
    "            scope=f\"activation_{1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_node(4)\n",
    "        self.add_node(5,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_2\").set_input([4]))  # activation cell 3\n",
    "        self.nodes[5]['subgraph'].name = \"activation_2\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, 16),\n",
    "            scope=f\"activation_{2}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_node(6)\n",
    "        # Todo add option here with a func which has a arg channels\n",
    "        self.add_node(7,\n",
    "                      subgraph=activation_cell.copy().set_scope(\"activation_3\").set_input([6]))  # activation cell 3\n",
    "        self.nodes[7]['subgraph'].name = \"activation_3\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, 16),\n",
    "            scope=f\"activation_{3}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (1, 2, EdgeData()),\n",
    "            (2, 3, EdgeData()),\n",
    "            (3, 4, EdgeData()),\n",
    "            (4, 5, EdgeData()),\n",
    "            (5, 6, EdgeData()),\n",
    "            (3, 6, EdgeData()),\n",
    "            (6, 7, EdgeData())\n",
    "        ])\n",
    "\n",
    "        self.edges[1, 2].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(3, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[3, 4].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "        self.edges[5, 6].set('op',\n",
    "                             ops.Sequential(nn.Conv2d(16, 16, 3, padding=1), ))  # convolutional edge\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 16,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(7, 4, activation_cell, conv_option)\n",
    "        self._create_base_block(11, 6, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 16,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        self._create_reduction_block(15, 8, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(19, 10, activation_cell, conv_option)\n",
    "        self._create_base_block(23, 12, activation_cell, conv_option)\n",
    "\n",
    "        conv_option_a = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        conv_option_b = {\n",
    "            \"in_channels\": 32,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 1,\n",
    "            \"padding\": 0,\n",
    "            \"stride\": 2\n",
    "        }\n",
    "        self._create_reduction_block(27, 14, activation_cell, conv_option_a, conv_option_b)\n",
    "\n",
    "        conv_option = {\n",
    "            \"in_channels\": 64,\n",
    "            \"out_channels\": 64,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": 1\n",
    "        }\n",
    "        self._create_base_block(31, 16, activation_cell, conv_option)\n",
    "        self._create_base_block(34, 18, activation_cell, conv_option)\n",
    "\n",
    "        # add head\n",
    "        self.add_node(39)\n",
    "        self.add_edges_from([\n",
    "            (38, 39, EdgeData())\n",
    "        ])\n",
    "        self.edges[38, 39].set('op',\n",
    "                               ops.Sequential(\n",
    "                                   nn.AvgPool2d(8),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64, 10),\n",
    "                                   nn.Softmax(dim=1)\n",
    "                               ))  # convolutional edge\n",
    "        self.add_node(40)\n",
    "        self.add_edges_from([\n",
    "            (39, 40, EdgeData().finalize())\n",
    "        ])\n",
    "\n",
    "    def _create_base_block(self, start: int, stage: int, cell, conv_option: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, conv_option[\"out_channels\"]),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, conv_option[\"out_channels\"]),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option), ))  # convolutional edge\n",
    "\n",
    "    def _create_reduction_block(self, start: int, stage: int, cell, conv_option_a: dict, conv_option_b: dict):\n",
    "        self.add_node(start + 1)\n",
    "\n",
    "        self.add_node(start + 2, subgraph=cell.copy().set_scope(f\"activation_{stage}\").set_input(\n",
    "            [start + 1]))  # activation cell 3\n",
    "        self.nodes[start + 2]['subgraph'].name = f\"activation_{stage}\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, conv_option_a[\"out_channels\"]),\n",
    "            scope=f\"activation_{stage}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_node(start + 3)\n",
    "\n",
    "        self.add_node(start + 4, subgraph=cell.copy().set_scope(f\"activation_{stage + 1}\").set_input(\n",
    "            [start + 3]))  # activation cell 3\n",
    "        self.nodes[start + 4]['subgraph'].name = f\"activation_{stage + 1}\"\n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_ops(edge, conv_option_b[\"out_channels\"]),\n",
    "            scope=f\"activation_{stage + 1}\",\n",
    "            private_edge_data=True, )\n",
    "\n",
    "        self.add_edges_from([\n",
    "            (start, start + 1, EdgeData()),\n",
    "            (start, start + 3, EdgeData()),  # add conv\n",
    "            (start + 1, start + 2, EdgeData()),\n",
    "            (start + 2, start + 3, EdgeData()),\n",
    "            (start + 3, start + 4, EdgeData()),\n",
    "        ])\n",
    "\n",
    "        self.edges[start, start + 1].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "        conv_option_a[\"in_channels\"] = conv_option_a[\"out_channels\"]\n",
    "        conv_option_a[\"stride\"] = 1\n",
    "\n",
    "        self.edges[start, start + 3].set('op',\n",
    "                                         ops.Sequential(nn.Conv2d(**conv_option_b), ))  # convolutional edge\n",
    "        self.edges[start + 2, start + 3].set('op',\n",
    "                                             ops.Sequential(nn.Conv2d(**conv_option_a), ))  # convolutional edge\n",
    "\n",
    "    def _set_ops(self, edge, channels=32):\n",
    "        # unary\n",
    "        if (edge.head, edge.tail) in {(1, 2), (1, 3)}:\n",
    "            edge.data.set(\"op\", [\n",
    "                ops.Identity(),\n",
    "                ops.Zero(stride=1),\n",
    "#                 Power(2),\n",
    "#                 Power(3),\n",
    "#                 Sqrt(),\n",
    "#                 Sin(),\n",
    "#                 Cos(),\n",
    "#                 Abs_op(),\n",
    "#                 Sign(),\n",
    "#                 Beta_mul(channels=channels),\n",
    "#                 Beta_add(channels=channels),\n",
    "#                 Log(),\n",
    "#                 Exp(),\n",
    "#                 Sinh(),\n",
    "#                 Cosh(),\n",
    "#                 Tanh(),\n",
    "#                 Asinh(),\n",
    "#                 Atan(),\n",
    "#                 Sinc(),\n",
    "#                 Maximum0(),\n",
    "#                 Minimum0(),\n",
    "#                 Sigmoid(),\n",
    "#                 LogExp(),\n",
    "#                 Exp2(),\n",
    "#                 Erf(),\n",
    "#                 Beta(channels=channels),\n",
    "            ])\n",
    "        # binary\n",
    "        elif (edge.head, edge.tail) in {(4, 5)}:\n",
    "            edge.data.set(\"op\", [\n",
    "#                 Add(),\n",
    "#                 Sub(),\n",
    "#                 Mul(),\n",
    "#                 Div(),\n",
    "                Maximum(),\n",
    "#                 Minimum(),\n",
    "#                 SigMul(),\n",
    "#                 ExpBetaSub2(channels=channels),\n",
    "#                 ExpBetaSubAbs(channels=channels),\n",
    "#                 BetaMix(channels=channels),\n",
    "            ]) \n",
    "        # testing\n",
    "        elif (edge.head, edge.tail) in {(2, 3)}:\n",
    "            edge.data.set(\"op\", [\n",
    "                  ops.Identity()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = ResNet20SearchSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/14 19:02:48 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mParsed graph:\n",
      "Graph activation_1:\n",
      " Graph(\n",
      "  (activation_1-edge(1,2)): Identity()\n",
      "  (activation_1-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_10:\n",
      " Graph(\n",
      "  (activation_10-edge(1,2)): Identity()\n",
      "  (activation_10-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_11:\n",
      " Graph(\n",
      "  (activation_11-edge(1,2)): Identity()\n",
      "  (activation_11-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_12:\n",
      " Graph(\n",
      "  (activation_12-edge(1,2)): Identity()\n",
      "  (activation_12-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_13:\n",
      " Graph(\n",
      "  (activation_13-edge(1,2)): Identity()\n",
      "  (activation_13-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_14:\n",
      " Graph(\n",
      "  (activation_14-edge(1,2)): Identity()\n",
      "  (activation_14-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_15:\n",
      " Graph(\n",
      "  (activation_15-edge(1,2)): Identity()\n",
      "  (activation_15-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_16:\n",
      " Graph(\n",
      "  (activation_16-edge(1,2)): Identity()\n",
      "  (activation_16-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_17:\n",
      " Graph(\n",
      "  (activation_17-edge(1,2)): Identity()\n",
      "  (activation_17-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_18:\n",
      " Graph(\n",
      "  (activation_18-edge(1,2)): Identity()\n",
      "  (activation_18-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_19:\n",
      " Graph(\n",
      "  (activation_19-edge(1,2)): Identity()\n",
      "  (activation_19-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_2:\n",
      " Graph(\n",
      "  (activation_2-edge(1,2)): Identity()\n",
      "  (activation_2-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_3:\n",
      " Graph(\n",
      "  (activation_3-edge(1,2)): Identity()\n",
      "  (activation_3-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_4:\n",
      " Graph(\n",
      "  (activation_4-edge(1,2)): Identity()\n",
      "  (activation_4-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_5:\n",
      " Graph(\n",
      "  (activation_5-edge(1,2)): Identity()\n",
      "  (activation_5-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_6:\n",
      " Graph(\n",
      "  (activation_6-edge(1,2)): Identity()\n",
      "  (activation_6-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_7:\n",
      " Graph(\n",
      "  (activation_7-edge(1,2)): Identity()\n",
      "  (activation_7-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_8:\n",
      " Graph(\n",
      "  (activation_8-edge(1,2)): Identity()\n",
      "  (activation_8-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph activation_9:\n",
      " Graph(\n",
      "  (activation_9-edge(1,2)): Identity()\n",
      "  (activation_9-edge(2,3)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "  )\n",
      ")\n",
      "==========\n",
      "Graph makrograph:\n",
      " ResNet20SearchSpace(\n",
      "  (makrograph-edge(1,2)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(2,3)): Identity()\n",
      "  (makrograph-subgraph_at(3)): Graph activation_1-0.7415744, scope activation_1, 3 nodes\n",
      "  (makrograph-edge(3,4)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(3,6)): Identity()\n",
      "  (makrograph-edge(4,5)): Identity()\n",
      "  (makrograph-subgraph_at(5)): Graph activation_2-0.3359166, scope activation_2, 3 nodes\n",
      "  (makrograph-edge(5,6)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(6,7)): Identity()\n",
      "  (makrograph-subgraph_at(7)): Graph activation_3-0.0456965, scope activation_3, 3 nodes\n",
      "  (makrograph-edge(7,8)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(7,10)): Identity()\n",
      "  (makrograph-edge(8,9)): Identity()\n",
      "  (makrograph-subgraph_at(9)): Graph activation_4-0.2808832, scope activation_4, 3 nodes\n",
      "  (makrograph-edge(9,10)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(10,11)): Identity()\n",
      "  (makrograph-subgraph_at(11)): Graph activation_5-0.2401304, scope activation_5, 3 nodes\n",
      "  (makrograph-edge(11,12)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(11,14)): Identity()\n",
      "  (makrograph-edge(12,13)): Identity()\n",
      "  (makrograph-subgraph_at(13)): Graph activation_6-0.9531293, scope activation_6, 3 nodes\n",
      "  (makrograph-edge(13,14)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(14,15)): Identity()\n",
      "  (makrograph-subgraph_at(15)): Graph activation_7-0.3522256, scope activation_7, 3 nodes\n",
      "  (makrograph-edge(15,16)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(15,18)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(16,17)): Identity()\n",
      "  (makrograph-subgraph_at(17)): Graph activation_8-0.2878779, scope activation_8, 3 nodes\n",
      "  (makrograph-edge(17,18)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(18,19)): Identity()\n",
      "  (makrograph-subgraph_at(19)): Graph activation_9-0.3592012, scope activation_9, 3 nodes\n",
      "  (makrograph-edge(19,20)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(19,22)): Identity()\n",
      "  (makrograph-edge(20,21)): Identity()\n",
      "  (makrograph-subgraph_at(21)): Graph activation_10-0.9469058, scope activation_10, 3 nodes\n",
      "  (makrograph-edge(21,22)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(22,23)): Identity()\n",
      "  (makrograph-subgraph_at(23)): Graph activation_11-0.6337479, scope activation_11, 3 nodes\n",
      "  (makrograph-edge(23,24)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(23,26)): Identity()\n",
      "  (makrograph-edge(24,25)): Identity()\n",
      "  (makrograph-subgraph_at(25)): Graph activation_12-0.6210768, scope activation_12, 3 nodes\n",
      "  (makrograph-edge(25,26)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(26,27)): Identity()\n",
      "  (makrograph-subgraph_at(27)): Graph activation_13-0.7156194, scope activation_13, 3 nodes\n",
      "  (makrograph-edge(27,28)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(27,30)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(28,29)): Identity()\n",
      "  (makrograph-subgraph_at(29)): Graph activation_14-0.3880172, scope activation_14, 3 nodes\n",
      "  (makrograph-edge(29,30)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(30,31)): Identity()\n",
      "  (makrograph-subgraph_at(31)): Graph activation_15-0.4144180, scope activation_15, 3 nodes\n",
      "  (makrograph-edge(31,32)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(31,34)): Identity()\n",
      "  (makrograph-edge(32,33)): Identity()\n",
      "  (makrograph-subgraph_at(33)): Graph activation_16-0.6508329, scope activation_16, 3 nodes\n",
      "  (makrograph-edge(33,34)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(34,35)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(34,37)): Identity()\n",
      "  (makrograph-subgraph_at(35)): Graph activation_17-0.0015242, scope activation_17, 3 nodes\n",
      "  (makrograph-edge(35,36)): Identity()\n",
      "  (makrograph-subgraph_at(36)): Graph activation_18-0.1923095, scope activation_18, 3 nodes\n",
      "  (makrograph-edge(36,37)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(37,38)): Identity()\n",
      "  (makrograph-subgraph_at(38)): Graph activation_19-0.3344017, scope activation_19, 3 nodes\n",
      "  (makrograph-edge(38,39)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(39,40)): Identity()\n",
      ")\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = DARTSOptimizer(config)\n",
    "optimizer.adapt_search_space(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/14 19:02:51 nl.defaults.trainer]: \u001b[0mparam size = 0.271690MB\n",
      "\u001b[32m[07/14 19:02:51 nl.defaults.trainer]: \u001b[0mStart training\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[07/14 19:02:52 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mArch weights (alphas, last column argmax): \n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "+0.000323, 0\n",
      "\u001b[32m[07/14 19:02:52 nl.defaults.trainer]: \u001b[0mEpoch 0-0, Train loss: 2.30280, validation loss: 2.30030, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:02:57 nl.defaults.trainer]: \u001b[0mEpoch 0-82, Train loss: 2.30537, validation loss: 2.30619, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:02 nl.defaults.trainer]: \u001b[0mEpoch 0-163, Train loss: 2.29887, validation loss: 2.29970, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:07 nl.defaults.trainer]: \u001b[0mEpoch 0-245, Train loss: 2.29870, validation loss: 2.30630, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:12 nl.defaults.trainer]: \u001b[0mEpoch 0-327, Train loss: 2.30095, validation loss: 2.29778, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:17 nl.defaults.trainer]: \u001b[0mEpoch 0-408, Train loss: 2.28915, validation loss: 2.30202, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:22 nl.defaults.trainer]: \u001b[0mEpoch 0-490, Train loss: 2.30317, validation loss: 2.29874, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:27 nl.defaults.trainer]: \u001b[0mEpoch 0-573, Train loss: 2.30895, validation loss: 2.30445, learning rate: [2e-05]\n",
      "\u001b[32m[07/14 19:03:32 nl.defaults.trainer]: \u001b[0mEpoch 0-654, Train loss: 2.29988, validation loss: 2.30168, learning rate: [2e-05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3764459/2031152707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/defaults/trainer.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, resume_from)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mdata_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mlogits_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/optimizers/oneshot/darts/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, data_train, data_val)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mlogits_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(optimizer, config)\n",
    "trainer.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASLib Project",
   "language": "python",
   "name": "naslib_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
