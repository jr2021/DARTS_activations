{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "device: cpu\n",
      "device: cuda:0\n",
      "device: cuda:0\n",
      "device: cuda:0\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from naslib.defaults.trainer import Trainer\n",
    "from naslib.optimizers import DARTSOptimizer\n",
    "from naslib.search_spaces import DartsSearchSpace\n",
    "from naslib.utils import utils, setup_logger, get_config_from_args, set_seed, log_args\n",
    "from naslib.search_spaces.core.graph import Graph, EdgeData\n",
    "from naslib.search_spaces.core import primitives as ops\n",
    "from torch import nn\n",
    "from fvcore.common.config import CfgNode\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from naslib.search_spaces.core.primitives import AbstractPrimitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='/project/dl2022s/robertsj/NASLib/naslib/benchmarks/nas_predictors/discrete_config.yaml', dist_backend='nccl', dist_url='tcp://127.0.0.1:8888', eval_only=False, gpu=None, model_path=None, multiprocessing_distributed=False, opts=[], rank=0, resume=False, seed=0, world_size=1)\n"
     ]
    }
   ],
   "source": [
    "config = utils.get_config_from_args(config_type='nas')\n",
    "config.optimizer = 'darts'\n",
    "utils.set_seed(config.seed)\n",
    "clear_output(wait=True)\n",
    "utils.log_args(config)\n",
    "\n",
    "logger = setup_logger(config.save + '/log.log')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stack():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, tensors, edges_data=None):\n",
    "        return torch.stack(tensors)\n",
    "\n",
    "\n",
    "class SimpleSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'a_stage_2'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        stages = ['a_stage_1', 'a_stage_2']\n",
    "\n",
    "        # cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'activation_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2) # intermediate node\n",
    "        activation_cell.add_node(3) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData())]) # mutable intermediate edge\n",
    "        activation_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable output edge\n",
    "\n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        for i, scope in zip(range(3, 5), stages):\n",
    "            self.add_node(i, subgraph=deepcopy(activation_cell).set_scope(scope).set_input([i-1])) # activation cell i\n",
    "            self.nodes[i]['subgraph'].name = scope\n",
    "        self.add_node(5) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 5)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[4, 5].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            )\n",
    "\n",
    "    def _set_ops(self, edge):\n",
    "        edge.data.set('op', [\n",
    "            ops.Sequential(nn.ReLU()),\n",
    "            ops.Sequential(nn.Hardswish()),\n",
    "            ops.Sequential(nn.LeakyReLU()),\n",
    "            ops.Sequential(nn.Identity())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maximum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.maximum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.minimum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "\n",
    "class stack():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, tensors, edges_data=None):\n",
    "        return torch.stack(tensors)\n",
    "\n",
    "\n",
    "class ComplexSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'u_stage_1',\n",
    "        'u_stage_2',\n",
    "        'b_stage_1'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        u_stages = ['u_stage_1', 'u_stage_2']\n",
    "        \n",
    "        # unary cell definition\n",
    "        unary_cell = Graph()\n",
    "        unary_cell.name = 'u_cell'\n",
    "        unary_cell.add_node(1) # input node\n",
    "        unary_cell.add_node(2) # intermediate node\n",
    "        unary_cell.add_node(3) # output node\n",
    "        unary_cell.add_edges_from([(1, 2, EdgeData())]) # mutable edge\n",
    "        unary_cell.edges[1, 2].set('cell_name', 'u_cell')\n",
    "        unary_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable edge\n",
    "        \n",
    "        # binary cell definition\n",
    "        binary_cell = Graph()\n",
    "        binary_cell.name = 'b_cell'\n",
    "        binary_cell.add_node(1) # input node\n",
    "        binary_cell.add_node(2) # input node\n",
    "        binary_cell.add_node(3) # concatination node\n",
    "        binary_cell.nodes[3]['comb_op'] = stack()\n",
    "        binary_cell.add_node(4) # intermediate node\n",
    "        binary_cell.add_node(5) # output node\n",
    "        binary_cell.add_edges_from([(3, 4, EdgeData())]) # mutable edge\n",
    "        binary_cell.edges[3, 4].set('cell_name', 'b_cell') \n",
    "        binary_cell.add_edges_from([(1, 3, EdgeData().finalize()),\n",
    "                                    (2, 3, EdgeData().finalize()),\n",
    "                                    (4, 5, EdgeData().finalize())]) # immutable edges\n",
    "        \n",
    "        # activation cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'a_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2, subgraph=deepcopy(unary_cell).set_scope('u_stage_1').set_input([1])) # unary node\n",
    "        activation_cell.nodes[2]['subgraph'].name = 'u_stage_1'\n",
    "        activation_cell.add_node(3, subgraph=deepcopy(unary_cell).set_scope('u_stage_2').set_input([1])) # unary node\n",
    "        activation_cell.nodes[3]['subgraph'].name = 'u_stage_2'\n",
    "        activation_cell.add_node(4, subgraph=deepcopy(binary_cell).set_scope('b_stage_1').set_input([2, 3])) # binary node\n",
    "        activation_cell.nodes[4]['subgraph'].name = 'b_stage_1'\n",
    "        activation_cell.add_node(5) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize()), \n",
    "                                        (1, 3, EdgeData().finalize()),\n",
    "                                        (2, 4, EdgeData().finalize()),\n",
    "                                        (3, 4, EdgeData().finalize()), \n",
    "                                        (4, 5, EdgeData().finalize())])\n",
    "        \n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        self.add_node(3, subgraph=deepcopy(activation_cell).set_input([2])) # activation cell\n",
    "        self.nodes[3]['subgraph'].name = 'a_stage_1'\n",
    "        self.add_node(4) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 4)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[3, 4].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in u_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_unary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            ) # set unary cell ops\n",
    "        \n",
    "        self.update_edges(\n",
    "            update_func=lambda edge: self._set_binary_ops(edge),\n",
    "            scope='b_stage_1',\n",
    "            private_edge_data=True\n",
    "        ) # set binary cell ops\n",
    "        \n",
    "\n",
    "    def _set_unary_ops(self, edge):\n",
    "        edge.data.set('op', [ops.Identity(), ops.Zero(stride=1)]) \n",
    "        \n",
    "        \n",
    "    def _set_binary_ops(self, edge):\n",
    "        edge.data.set('op', [Minimum(), Maximum()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Power(AbstractPrimitive):\n",
    "    def __init__(self,power):\n",
    "        super().__init__(locals())\n",
    "        self.power=power\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.pow(x,self.power)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sin(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sin(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Cos(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.cos(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Abs_op(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.abs(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sign(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x*-1\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_mul(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x * self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta_add(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return x + self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Log(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps = eps\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.log(x+self.eps)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Cosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.cosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Tanh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.tanh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Asinh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.asinh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Acosh(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.acosh(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Atan(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.atan(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sinc(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sinc(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.maximum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum0(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.minimum(x,torch.zeros(x.shape).cuda())\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Sigmoid(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sigmoid(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class LogExp(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.log(1+torch.exp(x))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Exp2(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-torch.pow(x,2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Erf(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.erf(x)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Beta(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return self.beta\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Add(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.add(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Sub(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.sub(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Mul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.mul(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Div(AbstractPrimitive):\n",
    "    def __init__(self,eps=1e-10):\n",
    "        super().__init__(locals())\n",
    "        self.eps=eps\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.div(x[0],x[1] + self.eps)\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class Maximum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.maximum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "    \n",
    "class Minimum(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.minimum(x[0],x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class SigMul(AbstractPrimitive):\n",
    "    def __init__(self):\n",
    "        super().__init__(locals())\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.mul(torch.sigmoid(x[0]),x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSub2(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.pow(torch.sub(x[0],x[1]),2))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class ExpBetaSubAbs(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.exp(-self.beta*torch.abs(torch.sub(x[0],x[1])))\n",
    "    def get_embedded_ops(self):\n",
    "        return None\n",
    "\n",
    "class BetaMix(AbstractPrimitive):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__(locals())\n",
    "        self.beta = torch.nn.Parameter(torch.ones(channels))\n",
    "    def forward(self,x, edge_data=None):\n",
    "        return torch.add(-self.beta*x[0],(1-self.beta)*x[1])\n",
    "    def get_embedded_ops(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNSearchSpace(Graph):\n",
    "\n",
    "    OPTIMIZER_SCOPE = [\n",
    "        'a_stage_1',\n",
    "        'u_stage_1',\n",
    "        'u_stage_2',\n",
    "        'u_stage_3',\n",
    "        'u_stage_4',\n",
    "        'b_stage_1',\n",
    "        'b_stage_2'\n",
    "    ]\n",
    "\n",
    "    QUERYABLE = False\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        u_stages = ['u_stage_1', 'u_stage_2', 'u_stage_3', 'u_stage_4']\n",
    "        b_stages = ['b_stage_1', 'b_stage_2']\n",
    "        \n",
    "        # unary cell definition\n",
    "        unary_cell = Graph()\n",
    "        unary_cell.name = 'u_cell'\n",
    "        unary_cell.add_node(1) # input node\n",
    "        unary_cell.add_node(2) # intermediate node\n",
    "        unary_cell.add_node(3) # output node\n",
    "        unary_cell.add_edges_from([(1, 2, EdgeData())]) # mutable edge\n",
    "        unary_cell.edges[1, 2].set('cell_name', 'u_cell')\n",
    "        unary_cell.add_edges_from([(2, 3, EdgeData().finalize())]) # immutable edge\n",
    "        \n",
    "        # binary cell definition\n",
    "        binary_cell = Graph()\n",
    "        binary_cell.name = 'b_cell'\n",
    "        binary_cell.add_node(1) # input node\n",
    "        binary_cell.add_node(2) # input node\n",
    "        binary_cell.add_node(3) # concatination node\n",
    "        binary_cell.nodes[3]['comb_op'] = stack()\n",
    "        binary_cell.add_node(4) # intermediate node\n",
    "        binary_cell.add_node(5) # output node\n",
    "        binary_cell.add_edges_from([(3, 4, EdgeData())]) # mutable edge\n",
    "        binary_cell.edges[3, 4].set('cell_name', 'b_cell') \n",
    "        binary_cell.add_edges_from([(1, 3, EdgeData().finalize()),\n",
    "                                    (2, 3, EdgeData().finalize()),\n",
    "                                    (4, 5, EdgeData().finalize())]) # immutable edges\n",
    "        \n",
    "        # activation cell definition\n",
    "        activation_cell = Graph()\n",
    "        activation_cell.name = 'a_cell'\n",
    "        activation_cell.add_node(1) # input node\n",
    "        activation_cell.add_node(2, subgraph=deepcopy(unary_cell).set_scope('u_stage_1').set_input([1])) # unary cell 1\n",
    "        activation_cell.nodes[2]['subgraph'].name = 'u_stage_1'\n",
    "        activation_cell.add_node(3, subgraph=deepcopy(unary_cell).set_scope('u_stage_2').set_input([1])) # unary cell 2\n",
    "        activation_cell.nodes[3]['subgraph'].name = 'u_stage_2'\n",
    "        activation_cell.add_node(4, subgraph=deepcopy(unary_cell).set_scope('u_stage_3').set_input([1])) # unary cell 3\n",
    "        activation_cell.nodes[4]['subgraph'].name = 'u_stage_3'\n",
    "        activation_cell.add_node(5, subgraph=deepcopy(binary_cell).set_scope('b_stage_1').set_input([2, 3])) # binary cell 1\n",
    "        activation_cell.nodes[5]['subgraph'].name = 'b_stage_1'\n",
    "        activation_cell.add_node(6, subgraph=deepcopy(unary_cell).set_scope('u_stage_4').set_input([5])) # unary cell 4\n",
    "        activation_cell.nodes[6]['subgraph'].name = 'u_stage_4'\n",
    "        activation_cell.add_node(7, subgraph=deepcopy(binary_cell).set_scope('b_stage_2').set_input([4, 6])) # binary cell 2\n",
    "        activation_cell.nodes[7]['subgraph'].name = 'b_stage_2'\n",
    "        activation_cell.add_node(8) # output node\n",
    "        activation_cell.add_edges_from([(1, 2, EdgeData().finalize()), \n",
    "                                        (1, 3, EdgeData().finalize()),\n",
    "                                        (1, 4, EdgeData().finalize()),\n",
    "                                        (2, 5, EdgeData().finalize()),\n",
    "                                        (3, 5, EdgeData().finalize()), \n",
    "                                        (4, 7, EdgeData().finalize()),\n",
    "                                        (5, 6, EdgeData().finalize()),\n",
    "                                        (6, 7, EdgeData().finalize()),\n",
    "                                        (7, 8, EdgeData().finalize())])\n",
    "        \n",
    "        # macroarchitecture definition\n",
    "        self.name = 'makrograph'\n",
    "        self.add_node(1) # input node\n",
    "        self.add_node(2) # intermediate node\n",
    "        self.add_node(3, subgraph=deepcopy(activation_cell).set_input([2])) # activation cell\n",
    "        self.nodes[3]['subgraph'].name = 'a_stage_1'\n",
    "        self.add_node(4) # output node\n",
    "        self.add_edges_from([(i, i+1, EdgeData()) for i in range(1, 4)])\n",
    "        self.edges[1, 2].set('op',\n",
    "            ops.Sequential(\n",
    "                nn.Conv2d(3, 6, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )) # convolutional edge\n",
    "        self.edges[3, 4].set('op', \n",
    "            ops.Sequential(\n",
    "                nn.Linear(400, 10), \n",
    "                nn.Softmax(dim=1)\n",
    "            )) # linear edge\n",
    "        \n",
    "        for scope in u_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_unary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True,\n",
    "            ) # set unary cell ops\n",
    "        \n",
    "        for scope in b_stages:\n",
    "            self.update_edges(\n",
    "                update_func=lambda edge: self._set_binary_ops(edge),\n",
    "                scope=scope,\n",
    "                private_edge_data=True\n",
    "            ) # set binary cell ops\n",
    "        \n",
    "\n",
    "    def _set_unary_ops(self, edge, channels=None):\n",
    "        edge.data.set('op', [\n",
    "            ops.Identity(), \n",
    "            ops.Zero(stride=1),\n",
    "            Sign(),\n",
    "            Abs_op(),\n",
    "            Power(2),\n",
    "            Power(3),\n",
    "#             Power(0.5),\n",
    "#             Beta_mul(channels),\n",
    "#             Beta_add(channels),\n",
    "#             Log(),\n",
    "            Exp(),\n",
    "            Sin(),\n",
    "            Cos(),\n",
    "            Sinh(),\n",
    "            Cosh(),\n",
    "            Tanh(),\n",
    "            Asinh(),\n",
    "#             Acosh(),\n",
    "            Atan(),\n",
    "            Sinc(),\n",
    "            Maximum0(),\n",
    "            Minimum0(),\n",
    "            Sigmoid(),\n",
    "            LogExp(),\n",
    "            Exp2(),\n",
    "            Erf(),\n",
    "#             Beta(channels)\n",
    "        ]) \n",
    "        \n",
    "        \n",
    "    def _set_binary_ops(self, edge, channels=None):\n",
    "        edge.data.set('op', [\n",
    "            Add(),\n",
    "            Sub(),\n",
    "            Mul(),\n",
    "            Div(),\n",
    "            Minimum(),\n",
    "            Maximum(),\n",
    "            SigMul(),\n",
    "#             ExpBetaSub2(channels),\n",
    "#             ExpBetaSubAbs(channels),\n",
    "#             BetaMix(channels)\n",
    "        ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = RNNSearchSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/04 14:25:37 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mParsed graph:\n",
      "Graph a_stage_1:\n",
      " Graph(\n",
      "  (a_stage_1-edge(1,2)): Identity()\n",
      "  (a_stage_1-edge(1,3)): Identity()\n",
      "  (a_stage_1-edge(1,4)): Identity()\n",
      "  (a_stage_1-subgraph_at(2)): Graph u_stage_1-0.0467797, scope u_stage_1, 3 nodes\n",
      "  (a_stage_1-edge(2,5)): Identity()\n",
      "  (a_stage_1-subgraph_at(3)): Graph u_stage_2-0.0467797, scope u_stage_2, 3 nodes\n",
      "  (a_stage_1-edge(3,5)): Identity()\n",
      "  (a_stage_1-subgraph_at(4)): Graph u_stage_3-0.0467797, scope u_stage_3, 3 nodes\n",
      "  (a_stage_1-edge(4,7)): Identity()\n",
      "  (a_stage_1-subgraph_at(5)): Graph b_stage_1-0.4453522, scope b_stage_1, 5 nodes\n",
      "  (a_stage_1-edge(5,6)): Identity()\n",
      "  (a_stage_1-subgraph_at(6)): Graph u_stage_4-0.0467797, scope u_stage_4, 3 nodes\n",
      "  (a_stage_1-edge(6,7)): Identity()\n",
      "  (a_stage_1-subgraph_at(7)): Graph b_stage_2-0.4453522, scope b_stage_2, 5 nodes\n",
      "  (a_stage_1-edge(7,8)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph b_stage_1:\n",
      " Graph(\n",
      "  (b_stage_1-edge(1,3)): Identity()\n",
      "  (b_stage_1-edge(2,3)): Identity()\n",
      "  (b_stage_1-edge(3,4)): MixedOp(\n",
      "    (primitive-0): Add()\n",
      "    (primitive-1): Sub()\n",
      "    (primitive-2): Mul()\n",
      "    (primitive-3): Div()\n",
      "    (primitive-4): Minimum()\n",
      "    (primitive-5): Maximum()\n",
      "    (primitive-6): SigMul()\n",
      "  )\n",
      "  (b_stage_1-edge(4,5)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph b_stage_2:\n",
      " Graph(\n",
      "  (b_stage_2-edge(1,3)): Identity()\n",
      "  (b_stage_2-edge(2,3)): Identity()\n",
      "  (b_stage_2-edge(3,4)): MixedOp(\n",
      "    (primitive-0): Add()\n",
      "    (primitive-1): Sub()\n",
      "    (primitive-2): Mul()\n",
      "    (primitive-3): Div()\n",
      "    (primitive-4): Minimum()\n",
      "    (primitive-5): Maximum()\n",
      "    (primitive-6): SigMul()\n",
      "  )\n",
      "  (b_stage_2-edge(4,5)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_1:\n",
      " Graph(\n",
      "  (u_stage_1-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "    (primitive-2): Sign()\n",
      "    (primitive-3): Abs_op()\n",
      "    (primitive-4): Power()\n",
      "    (primitive-5): Power()\n",
      "    (primitive-6): Exp()\n",
      "    (primitive-7): Sin()\n",
      "    (primitive-8): Cos()\n",
      "    (primitive-9): Sinh()\n",
      "    (primitive-10): Cosh()\n",
      "    (primitive-11): Tanh()\n",
      "    (primitive-12): Asinh()\n",
      "    (primitive-13): Atan()\n",
      "    (primitive-14): Sinc()\n",
      "    (primitive-15): Maximum0()\n",
      "    (primitive-16): Minimum0()\n",
      "    (primitive-17): Sigmoid()\n",
      "    (primitive-18): LogExp()\n",
      "    (primitive-19): Exp2()\n",
      "    (primitive-20): Erf()\n",
      "  )\n",
      "  (u_stage_1-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_2:\n",
      " Graph(\n",
      "  (u_stage_2-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "    (primitive-2): Sign()\n",
      "    (primitive-3): Abs_op()\n",
      "    (primitive-4): Power()\n",
      "    (primitive-5): Power()\n",
      "    (primitive-6): Exp()\n",
      "    (primitive-7): Sin()\n",
      "    (primitive-8): Cos()\n",
      "    (primitive-9): Sinh()\n",
      "    (primitive-10): Cosh()\n",
      "    (primitive-11): Tanh()\n",
      "    (primitive-12): Asinh()\n",
      "    (primitive-13): Atan()\n",
      "    (primitive-14): Sinc()\n",
      "    (primitive-15): Maximum0()\n",
      "    (primitive-16): Minimum0()\n",
      "    (primitive-17): Sigmoid()\n",
      "    (primitive-18): LogExp()\n",
      "    (primitive-19): Exp2()\n",
      "    (primitive-20): Erf()\n",
      "  )\n",
      "  (u_stage_2-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_3:\n",
      " Graph(\n",
      "  (u_stage_3-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "    (primitive-2): Sign()\n",
      "    (primitive-3): Abs_op()\n",
      "    (primitive-4): Power()\n",
      "    (primitive-5): Power()\n",
      "    (primitive-6): Exp()\n",
      "    (primitive-7): Sin()\n",
      "    (primitive-8): Cos()\n",
      "    (primitive-9): Sinh()\n",
      "    (primitive-10): Cosh()\n",
      "    (primitive-11): Tanh()\n",
      "    (primitive-12): Asinh()\n",
      "    (primitive-13): Atan()\n",
      "    (primitive-14): Sinc()\n",
      "    (primitive-15): Maximum0()\n",
      "    (primitive-16): Minimum0()\n",
      "    (primitive-17): Sigmoid()\n",
      "    (primitive-18): LogExp()\n",
      "    (primitive-19): Exp2()\n",
      "    (primitive-20): Erf()\n",
      "  )\n",
      "  (u_stage_3-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph u_stage_4:\n",
      " Graph(\n",
      "  (u_stage_4-edge(1,2)): MixedOp(\n",
      "    (primitive-0): Identity()\n",
      "    (primitive-1): Zero (stride=1)\n",
      "    (primitive-2): Sign()\n",
      "    (primitive-3): Abs_op()\n",
      "    (primitive-4): Power()\n",
      "    (primitive-5): Power()\n",
      "    (primitive-6): Exp()\n",
      "    (primitive-7): Sin()\n",
      "    (primitive-8): Cos()\n",
      "    (primitive-9): Sinh()\n",
      "    (primitive-10): Cosh()\n",
      "    (primitive-11): Tanh()\n",
      "    (primitive-12): Asinh()\n",
      "    (primitive-13): Atan()\n",
      "    (primitive-14): Sinc()\n",
      "    (primitive-15): Maximum0()\n",
      "    (primitive-16): Minimum0()\n",
      "    (primitive-17): Sigmoid()\n",
      "    (primitive-18): LogExp()\n",
      "    (primitive-19): Exp2()\n",
      "    (primitive-20): Erf()\n",
      "  )\n",
      "  (u_stage_4-edge(2,3)): Identity()\n",
      ")\n",
      "==========\n",
      "Graph makrograph:\n",
      " RNNSearchSpace(\n",
      "  (makrograph-edge(1,2)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (makrograph-edge(2,3)): Identity()\n",
      "  (makrograph-subgraph_at(3)): Graph a_stage_1-0.2592269, scope None, 8 nodes\n",
      "  (makrograph-edge(3,4)): Sequential(\n",
      "    (op): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=10, bias=True)\n",
      "      (1): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = DARTSOptimizer(config)\n",
    "optimizer.adapt_search_space(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/04 14:25:40 nl.defaults.trainer]: \u001b[0mparam size = 0.006882MB\n",
      "\u001b[32m[07/04 14:25:40 nl.defaults.trainer]: \u001b[0mStart training\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[07/04 14:25:41 nl.optimizers.oneshot.darts.optimizer]: \u001b[0mArch weights (alphas, last column argmax): \n",
      "+0.001590, -0.000726, -0.001156, +0.001044, -0.000165, +0.000628, -0.000305, 0\n",
      "-0.000143, +0.000711, -0.000879, -0.000593, +0.000674, +0.000690, -0.000997, 1\n",
      "+0.000266, -0.000916, +0.000696, +0.000741, +0.001266, -0.001623, +0.000183, -0.000675, +0.000176, -0.000330, +0.000302, +0.000080, +0.000234, -0.001364, -0.000962, +0.000270, +0.000273, -0.000181, -0.000370, -0.001080, -0.000125, 4\n",
      "+0.002006, -0.000984, -0.000772, -0.000796, +0.001256, -0.000275, -0.000914, +0.001006, -0.001760, -0.000923, +0.000914, -0.000407, +0.000984, -0.000541, +0.000173, -0.001080, -0.000163, +0.000123, -0.000198, +0.000291, -0.000324, 0\n",
      "-0.000489, -0.000153, -0.000786, +0.000496, -0.000106, +0.001298, +0.001919, +0.001698, -0.000330, +0.000626, -0.000089, -0.000188, -0.000070, -0.000158, -0.001168, +0.001807, +0.000220, -0.000836, +0.000562, +0.001221, -0.001458, 6\n",
      "+0.001047, -0.001536, +0.001451, -0.000938, -0.000730, +0.000733, +0.000032, +0.000509, -0.000130, +0.000285, +0.000182, -0.000766, +0.001113, -0.000927, -0.000324, -0.000579, -0.000016, +0.001197, +0.001902, +0.001615, +0.001179, 18\n",
      "\u001b[32m[07/04 14:25:41 nl.defaults.trainer]: \u001b[0mEpoch 0-0, Train loss: 2.30066, validation loss: 2.30206, learning rate: [0.025]\n",
      "\u001b[32m[07/04 14:25:46 nl.defaults.trainer]: \u001b[0mEpoch 0-25, Train loss: nan, validation loss: nan, learning rate: [0.025]\n",
      "\u001b[32m[07/04 14:25:52 nl.defaults.trainer]: \u001b[0mEpoch 0-51, Train loss: nan, validation loss: nan, learning rate: [0.025]\n",
      "\u001b[32m[07/04 14:25:57 nl.defaults.trainer]: \u001b[0mEpoch 0-77, Train loss: nan, validation loss: nan, learning rate: [0.025]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2448757/2031152707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/dl2022s/robertsj/NASLib/naslib/defaults/trainer.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, resume_from)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_step_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mdata_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/dl2022s/robertsj/miniconda3/envs/naslib_project/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(optimizer, config)\n",
    "trainer.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate_oneshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASLib Project",
   "language": "python",
   "name": "naslib_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
